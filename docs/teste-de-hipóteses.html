<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 6 Teste de Hipóteses | Inferência Estatística com R</title>
  <meta name="description" content="Uma abrangente introdução aos métodos de estatística inferencial usando o R. Adquira o raciocínio necessário para extrair conclusões a partir de uma amostra usando exemplos reais." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 6 Teste de Hipóteses | Inferência Estatística com R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://paulamacaira.github.io/livro_inferencia_com_R/" />
  <meta property="og:image" content="https://paulamacaira.github.io/livro_inferencia_com_R/cover.png" />
  <meta property="og:description" content="Uma abrangente introdução aos métodos de estatística inferencial usando o R. Adquira o raciocínio necessário para extrair conclusões a partir de uma amostra usando exemplos reais." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 6 Teste de Hipóteses | Inferência Estatística com R" />
  
  <meta name="twitter:description" content="Uma abrangente introdução aos métodos de estatística inferencial usando o R. Adquira o raciocínio necessário para extrair conclusões a partir de uma amostra usando exemplos reais." />
  <meta name="twitter:image" content="https://paulamacaira.github.io/livro_inferencia_com_R/cover.png" />

<meta name="author" content="P. Maçaira, L. Bastos, S. Aguilar &amp; I. Peres" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="intervalo-de-confiança.html"/>
<link rel="next" href="inferência-estatística-para-duas-populações.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Inferência Estatística com R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefácio</a></li>
<li class="chapter" data-level="1" data-path="analise_descritiva.html"><a href="analise_descritiva.html"><i class="fa fa-check"></i><b>1</b> Análise Descritiva</a>
<ul>
<li class="chapter" data-level="1.1" data-path="analise_descritiva.html"><a href="analise_descritiva.html#coleta-e-armazenamento-de-dados"><i class="fa fa-check"></i><b>1.1</b> Coleta e Armazenamento de Dados</a></li>
<li class="chapter" data-level="1.2" data-path="analise_descritiva.html"><a href="analise_descritiva.html#tipos-de-variáveis"><i class="fa fa-check"></i><b>1.2</b> Tipos de Variáveis</a></li>
<li class="chapter" data-level="1.3" data-path="analise_descritiva.html"><a href="analise_descritiva.html#variáveis-quantitativas"><i class="fa fa-check"></i><b>1.3</b> Variáveis Quantitativas</a></li>
<li class="chapter" data-level="1.4" data-path="analise_descritiva.html"><a href="analise_descritiva.html#variáveis-qualitativas-ou-categóricas"><i class="fa fa-check"></i><b>1.4</b> Variáveis Qualitativas (ou categóricas)</a></li>
<li class="chapter" data-level="1.5" data-path="analise_descritiva.html"><a href="analise_descritiva.html#medidas-de-tendência-central"><i class="fa fa-check"></i><b>1.5</b> Medidas de Tendência Central</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="analise_descritiva.html"><a href="analise_descritiva.html#média-aritmética-simples"><i class="fa fa-check"></i><b>1.5.1</b> Média Aritmética Simples</a></li>
<li class="chapter" data-level="1.5.2" data-path="analise_descritiva.html"><a href="analise_descritiva.html#mediana"><i class="fa fa-check"></i><b>1.5.2</b> Mediana</a></li>
<li class="chapter" data-level="1.5.3" data-path="analise_descritiva.html"><a href="analise_descritiva.html#moda"><i class="fa fa-check"></i><b>1.5.3</b> Moda</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="analise_descritiva.html"><a href="analise_descritiva.html#medidas-de-variabilidade"><i class="fa fa-check"></i><b>1.6</b> Medidas de Variabilidade</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="analise_descritiva.html"><a href="analise_descritiva.html#amplitude-total"><i class="fa fa-check"></i><b>1.6.1</b> Amplitude Total</a></li>
<li class="chapter" data-level="1.6.2" data-path="analise_descritiva.html"><a href="analise_descritiva.html#desvio-padrão"><i class="fa fa-check"></i><b>1.6.2</b> Desvio Padrão</a></li>
<li class="chapter" data-level="1.6.3" data-path="analise_descritiva.html"><a href="analise_descritiva.html#coeficiente-de-variação"><i class="fa fa-check"></i><b>1.6.3</b> Coeficiente de Variação</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="analise_descritiva.html"><a href="analise_descritiva.html#medidas-de-posição"><i class="fa fa-check"></i><b>1.7</b> Medidas de Posição</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="analise_descritiva.html"><a href="analise_descritiva.html#percentis"><i class="fa fa-check"></i><b>1.7.1</b> Percentis</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="analise_descritiva.html"><a href="analise_descritiva.html#referências"><i class="fa fa-check"></i><b>1.8</b> Referências</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="análise-gráfica.html"><a href="análise-gráfica.html"><i class="fa fa-check"></i><b>2</b> Análise Gráfica</a>
<ul>
<li class="chapter" data-level="2.1" data-path="análise-gráfica.html"><a href="análise-gráfica.html#variáveis-qualitativas---nominais-e-ordinais"><i class="fa fa-check"></i><b>2.1</b> Variáveis Qualitativas - Nominais e Ordinais</a></li>
<li class="chapter" data-level="2.2" data-path="análise-gráfica.html"><a href="análise-gráfica.html#variáveis-quantitativas-discretas"><i class="fa fa-check"></i><b>2.2</b> Variáveis Quantitativas Discretas</a></li>
<li class="chapter" data-level="2.3" data-path="análise-gráfica.html"><a href="análise-gráfica.html#variáveis-quantitativas-contínuas"><i class="fa fa-check"></i><b>2.3</b> Variáveis Quantitativas Contínuas</a></li>
<li class="chapter" data-level="2.4" data-path="análise-gráfica.html"><a href="análise-gráfica.html#histograma"><i class="fa fa-check"></i><b>2.4</b> Histograma</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="análise-gráfica.html"><a href="análise-gráfica.html#tendência-central"><i class="fa fa-check"></i><b>2.4.1</b> Tendência Central</a></li>
<li class="chapter" data-level="2.4.2" data-path="análise-gráfica.html"><a href="análise-gráfica.html#variabilidade"><i class="fa fa-check"></i><b>2.4.2</b> Variabilidade</a></li>
<li class="chapter" data-level="2.4.3" data-path="análise-gráfica.html"><a href="análise-gráfica.html#forma"><i class="fa fa-check"></i><b>2.4.3</b> Forma</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="análise-gráfica.html"><a href="análise-gráfica.html#boxplot"><i class="fa fa-check"></i><b>2.5</b> Boxplot</a></li>
<li class="chapter" data-level="2.6" data-path="análise-gráfica.html"><a href="análise-gráfica.html#diagrama-de-dispersão"><i class="fa fa-check"></i><b>2.6</b> Diagrama de Dispersão</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="análise-gráfica.html"><a href="análise-gráfica.html#exemplo-1"><i class="fa fa-check"></i><b>2.6.1</b> Exemplo 1</a></li>
<li class="chapter" data-level="2.6.2" data-path="análise-gráfica.html"><a href="análise-gráfica.html#exemplo-2"><i class="fa fa-check"></i><b>2.6.2</b> Exemplo 2</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="análise-gráfica.html"><a href="análise-gráfica.html#séries-temporais"><i class="fa fa-check"></i><b>2.7</b> Séries Temporais</a></li>
<li class="chapter" data-level="2.8" data-path="análise-gráfica.html"><a href="análise-gráfica.html#gráfico-de-radar"><i class="fa fa-check"></i><b>2.8</b> Gráfico de Radar</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="conceitos-básicos.html"><a href="conceitos-básicos.html"><i class="fa fa-check"></i><b>3</b> Conceitos Básicos</a>
<ul>
<li class="chapter" data-level="3.1" data-path="conceitos-básicos.html"><a href="conceitos-básicos.html#população"><i class="fa fa-check"></i><b>3.1</b> População</a></li>
<li class="chapter" data-level="3.2" data-path="conceitos-básicos.html"><a href="conceitos-básicos.html#amostra"><i class="fa fa-check"></i><b>3.2</b> Amostra</a></li>
<li class="chapter" data-level="3.3" data-path="conceitos-básicos.html"><a href="conceitos-básicos.html#estatísticas-e-parâmetros"><i class="fa fa-check"></i><b>3.3</b> Estatísticas e Parâmetros</a></li>
<li class="chapter" data-level="3.4" data-path="conceitos-básicos.html"><a href="conceitos-básicos.html#distribuições-amostrais"><i class="fa fa-check"></i><b>3.4</b> Distribuições Amostrais</a></li>
<li class="chapter" data-level="3.5" data-path="conceitos-básicos.html"><a href="conceitos-básicos.html#propriedades-dos-estimadores"><i class="fa fa-check"></i><b>3.5</b> Propriedades dos Estimadores</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="distribuições-amostrais-1.html"><a href="distribuições-amostrais-1.html"><i class="fa fa-check"></i><b>4</b> Distribuições Amostrais</a>
<ul>
<li class="chapter" data-level="4.1" data-path="distribuições-amostrais-1.html"><a href="distribuições-amostrais-1.html#distribuição-da-média-amostral"><i class="fa fa-check"></i><b>4.1</b> Distribuição da Média Amostral</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="distribuições-amostrais-1.html"><a href="distribuições-amostrais-1.html#visualizando"><i class="fa fa-check"></i><b>4.1.1</b> Visualizando</a></li>
<li class="chapter" data-level="4.1.2" data-path="distribuições-amostrais-1.html"><a href="distribuições-amostrais-1.html#prova"><i class="fa fa-check"></i><b>4.1.2</b> Prova</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="distribuições-amostrais-1.html"><a href="distribuições-amostrais-1.html#teorema-central-do-limite"><i class="fa fa-check"></i><b>4.2</b> Teorema Central do Limite</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="distribuições-amostrais-1.html"><a href="distribuições-amostrais-1.html#visualizando-1"><i class="fa fa-check"></i><b>4.2.1</b> Visualizando</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="distribuições-amostrais-1.html"><a href="distribuições-amostrais-1.html#distribuição-da-variância-amostral"><i class="fa fa-check"></i><b>4.3</b> Distribuição da Variância Amostral</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="distribuições-amostrais-1.html"><a href="distribuições-amostrais-1.html#distribuição-qui-quadrado"><i class="fa fa-check"></i><b>4.3.1</b> Distribuição Qui-quadrado</a></li>
<li class="chapter" data-level="4.3.2" data-path="distribuições-amostrais-1.html"><a href="distribuições-amostrais-1.html#visualizando-2"><i class="fa fa-check"></i><b>4.3.2</b> Visualizando</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="distribuições-amostrais-1.html"><a href="distribuições-amostrais-1.html#distribuição-da-proporção-amostral"><i class="fa fa-check"></i><b>4.4</b> Distribuição da Proporção Amostral</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="distribuições-amostrais-1.html"><a href="distribuições-amostrais-1.html#visualizando-3"><i class="fa fa-check"></i><b>4.4.1</b> Visualizando</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="intervalo-de-confiança.html"><a href="intervalo-de-confiança.html"><i class="fa fa-check"></i><b>5</b> Intervalo de Confiança</a>
<ul>
<li class="chapter" data-level="5.1" data-path="intervalo-de-confiança.html"><a href="intervalo-de-confiança.html#ideia-geral"><i class="fa fa-check"></i><b>5.1</b> Ideia Geral</a></li>
<li class="chapter" data-level="5.2" data-path="intervalo-de-confiança.html"><a href="intervalo-de-confiança.html#i.c.-para-a-média-de-uma-normal-com-variância-conhecida"><i class="fa fa-check"></i><b>5.2</b> I.C. para a média de uma Normal com variância conhecida</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="intervalo-de-confiança.html"><a href="intervalo-de-confiança.html#construindo-o-intervalo-de-confiança"><i class="fa fa-check"></i><b>5.2.1</b> Construindo o intervalo de confiança</a></li>
<li class="chapter" data-level="5.2.2" data-path="intervalo-de-confiança.html"><a href="intervalo-de-confiança.html#margem-de-erro"><i class="fa fa-check"></i><b>5.2.2</b> Margem de Erro</a></li>
<li class="chapter" data-level="5.2.3" data-path="intervalo-de-confiança.html"><a href="intervalo-de-confiança.html#determinação-do-tamanho-da-amostra"><i class="fa fa-check"></i><b>5.2.3</b> Determinação do tamanho da amostra</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="intervalo-de-confiança.html"><a href="intervalo-de-confiança.html#i.c.-para-a-média-de-uma-normal-com-variância-desconhecida"><i class="fa fa-check"></i><b>5.3</b> I.C. para a média de uma Normal com variância desconhecida</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="intervalo-de-confiança.html"><a href="intervalo-de-confiança.html#construindo-o-intervalo-de-confiança-1"><i class="fa fa-check"></i><b>5.3.1</b> Construindo o intervalo de confiança</a></li>
<li class="chapter" data-level="5.3.2" data-path="intervalo-de-confiança.html"><a href="intervalo-de-confiança.html#margem-de-erro-1"><i class="fa fa-check"></i><b>5.3.2</b> Margem de Erro</a></li>
<li class="chapter" data-level="5.3.3" data-path="intervalo-de-confiança.html"><a href="intervalo-de-confiança.html#determinação-do-tamanho-da-amostra-1"><i class="fa fa-check"></i><b>5.3.3</b> Determinação do tamanho da amostra</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="intervalo-de-confiança.html"><a href="intervalo-de-confiança.html#i.c.-para-a-proporção-populacional"><i class="fa fa-check"></i><b>5.4</b> I.C. para a proporção populacional</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="intervalo-de-confiança.html"><a href="intervalo-de-confiança.html#construindo-o-intervalo-de-confiança-2"><i class="fa fa-check"></i><b>5.4.1</b> Construindo o intervalo de confiança</a></li>
<li class="chapter" data-level="5.4.2" data-path="intervalo-de-confiança.html"><a href="intervalo-de-confiança.html#margem-de-erro-2"><i class="fa fa-check"></i><b>5.4.2</b> Margem de Erro</a></li>
<li class="chapter" data-level="5.4.3" data-path="intervalo-de-confiança.html"><a href="intervalo-de-confiança.html#determinação-do-tamanho-da-amostra-2"><i class="fa fa-check"></i><b>5.4.3</b> Determinação do tamanho da amostra</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="intervalo-de-confiança.html"><a href="intervalo-de-confiança.html#intervalo-de-confiança-para-a-variância-de-uma-normal"><i class="fa fa-check"></i><b>5.5</b> Intervalo de confiança para a variância de uma Normal</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="intervalo-de-confiança.html"><a href="intervalo-de-confiança.html#construindo-o-intervalo-de-confiança-3"><i class="fa fa-check"></i><b>5.5.1</b> Construindo o intervalo de confiança</a></li>
<li class="chapter" data-level="5.5.2" data-path="intervalo-de-confiança.html"><a href="intervalo-de-confiança.html#margem-de-erro-3"><i class="fa fa-check"></i><b>5.5.2</b> Margem de Erro</a></li>
<li class="chapter" data-level="5.5.3" data-path="intervalo-de-confiança.html"><a href="intervalo-de-confiança.html#determinação-do-tamanho-da-amostra-3"><i class="fa fa-check"></i><b>5.5.3</b> Determinação do tamanho da amostra</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html"><i class="fa fa-check"></i><b>6</b> Teste de Hipóteses</a>
<ul>
<li class="chapter" data-level="6.1" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#ideia-geral-1"><i class="fa fa-check"></i><b>6.1</b> Ideia Geral</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#hipótese-nula"><i class="fa fa-check"></i><b>6.1.1</b> Hipótese nula</a></li>
<li class="chapter" data-level="6.1.2" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#hipótese-alternativa"><i class="fa fa-check"></i><b>6.1.2</b> Hipótese alternativa</a></li>
<li class="chapter" data-level="6.1.3" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#estatística-de-teste"><i class="fa fa-check"></i><b>6.1.3</b> Estatística de teste</a></li>
<li class="chapter" data-level="6.1.4" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#tipos-de-erro"><i class="fa fa-check"></i><b>6.1.4</b> Tipos de erro</a></li>
<li class="chapter" data-level="6.1.5" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#regra-de-decisão"><i class="fa fa-check"></i><b>6.1.5</b> Regra de decisão</a></li>
<li class="chapter" data-level="6.1.6" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#região-crítica"><i class="fa fa-check"></i><b>6.1.6</b> Região crítica</a></li>
<li class="chapter" data-level="6.1.7" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#cco-e-poder-do-teste"><i class="fa fa-check"></i><b>6.1.7</b> CCO e Poder do Teste</a></li>
<li class="chapter" data-level="6.1.8" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#exemplo"><i class="fa fa-check"></i><b>6.1.8</b> Exemplo</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#t.h.-para-a-média-de-uma-normal-com-variância-conhecida"><i class="fa fa-check"></i><b>6.2</b> T.H. para a média de uma Normal com variância conhecida</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#construindo-o-teste-de-hipóteses"><i class="fa fa-check"></i><b>6.2.1</b> Construindo o teste de hipóteses</a></li>
<li class="chapter" data-level="6.2.2" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#teste-de-hipóteses-vs-intervalo-de-confiança"><i class="fa fa-check"></i><b>6.2.2</b> Teste de Hipóteses vs Intervalo de Confiança</a></li>
<li class="chapter" data-level="6.2.3" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#valor-p-ou-p-valor"><i class="fa fa-check"></i><b>6.2.3</b> Valor P (ou p-valor)</a></li>
<li class="chapter" data-level="6.2.4" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#exemplo-3"><i class="fa fa-check"></i><b>6.2.4</b> Exemplo</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#t.h.-para-a-média-de-uma-normal-com-variância-desconhecida"><i class="fa fa-check"></i><b>6.3</b> T.H. para a média de uma Normal com variância desconhecida</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#construindo-o-teste-de-hipóteses-1"><i class="fa fa-check"></i><b>6.3.1</b> Construindo o teste de hipóteses</a></li>
<li class="chapter" data-level="6.3.2" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#valor-p-ou-p-valor-1"><i class="fa fa-check"></i><b>6.3.2</b> Valor P (ou p-valor)</a></li>
<li class="chapter" data-level="6.3.3" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#exemplo-4"><i class="fa fa-check"></i><b>6.3.3</b> Exemplo</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#t.h.-para-a-proporção-populacional"><i class="fa fa-check"></i><b>6.4</b> T.H. para a proporção populacional</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#construindo-o-teste-de-hipóteses-2"><i class="fa fa-check"></i><b>6.4.1</b> Construindo o teste de hipóteses</a></li>
<li class="chapter" data-level="6.4.2" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#valor-p-ou-p-valor-2"><i class="fa fa-check"></i><b>6.4.2</b> Valor P (ou p-valor)</a></li>
<li class="chapter" data-level="6.4.3" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#exemplo-5"><i class="fa fa-check"></i><b>6.4.3</b> Exemplo</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#t.h.-para-a-variância-de-uma-normal"><i class="fa fa-check"></i><b>6.5</b> T.H. para a variância de uma Normal</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#construindo-o-teste-de-hipóteses-3"><i class="fa fa-check"></i><b>6.5.1</b> Construindo o teste de hipóteses</a></li>
<li class="chapter" data-level="6.5.2" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#valor-p"><i class="fa fa-check"></i><b>6.5.2</b> Valor P</a></li>
<li class="chapter" data-level="6.5.3" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#exemplo-6"><i class="fa fa-check"></i><b>6.5.3</b> Exemplo</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#t.h.-adequação-de-ajuste-goodness-of-fit"><i class="fa fa-check"></i><b>6.6</b> T.H. Adequação de Ajuste (Goodness of Fit)</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#construindo-o-teste-de-hipóteses-4"><i class="fa fa-check"></i><b>6.6.1</b> Construindo o teste de hipóteses</a></li>
<li class="chapter" data-level="6.6.2" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#exemplo-7"><i class="fa fa-check"></i><b>6.6.2</b> Exemplo</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#t.h.-para-a-tabela-de-contingência"><i class="fa fa-check"></i><b>6.7</b> T.H. para a Tabela de Contingência</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#construindo-o-teste-de-hipóteses-5"><i class="fa fa-check"></i><b>6.7.1</b> Construindo o teste de hipóteses</a></li>
<li class="chapter" data-level="6.7.2" data-path="teste-de-hipóteses.html"><a href="teste-de-hipóteses.html#exemplo-8"><i class="fa fa-check"></i><b>6.7.2</b> Exemplo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="inferência-estatística-para-duas-populações.html"><a href="inferência-estatística-para-duas-populações.html"><i class="fa fa-check"></i><b>7</b> Inferência Estatística para Duas Populações</a>
<ul>
<li class="chapter" data-level="7.1" data-path="inferência-estatística-para-duas-populações.html"><a href="inferência-estatística-para-duas-populações.html#comparação-das-médias-de-distribuições-normais"><i class="fa fa-check"></i><b>7.1</b> Comparação das médias de distribuições Normais</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="inferência-estatística-para-duas-populações.html"><a href="inferência-estatística-para-duas-populações.html#variâncias-conhecidas"><i class="fa fa-check"></i><b>7.1.1</b> Variâncias Conhecidas</a></li>
<li class="chapter" data-level="7.1.2" data-path="inferência-estatística-para-duas-populações.html"><a href="inferência-estatística-para-duas-populações.html#variâncias-desconhecidas"><i class="fa fa-check"></i><b>7.1.2</b> Variâncias Desconhecidas</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="inferência-estatística-para-duas-populações.html"><a href="inferência-estatística-para-duas-populações.html#comparação-das-variâncias-de-distribuições-normais"><i class="fa fa-check"></i><b>7.2</b> Comparação das variâncias de distribuições Normais</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="inferência-estatística-para-duas-populações.html"><a href="inferência-estatística-para-duas-populações.html#teste-de-hipóteses-2"><i class="fa fa-check"></i><b>7.2.1</b> Teste de hipóteses</a></li>
<li class="chapter" data-level="7.2.2" data-path="inferência-estatística-para-duas-populações.html"><a href="inferência-estatística-para-duas-populações.html#intervalo-de-confiança-2"><i class="fa fa-check"></i><b>7.2.2</b> Intervalo de Confiança</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="inferência-estatística-para-duas-populações.html"><a href="inferência-estatística-para-duas-populações.html#comparação-das-proporções-populacionais"><i class="fa fa-check"></i><b>7.3</b> Comparação das proporções populacionais</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="inferência-estatística-para-duas-populações.html"><a href="inferência-estatística-para-duas-populações.html#teste-de-hipóteses-3"><i class="fa fa-check"></i><b>7.3.1</b> Teste de hipóteses</a></li>
<li class="chapter" data-level="7.3.2" data-path="inferência-estatística-para-duas-populações.html"><a href="inferência-estatística-para-duas-populações.html#intervalo-de-confiança-3"><i class="fa fa-check"></i><b>7.3.2</b> Intervalo de Confiança</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="análise-de-variância-anova.html"><a href="análise-de-variância-anova.html"><i class="fa fa-check"></i><b>8</b> Análise de Variância (ANOVA)</a>
<ul>
<li class="chapter" data-level="8.1" data-path="análise-de-variância-anova.html"><a href="análise-de-variância-anova.html#anova-para-um-único-fator"><i class="fa fa-check"></i><b>8.1</b> ANOVA para um único fator</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="análise-de-variância-anova.html"><a href="análise-de-variância-anova.html#partição-da-variabilidade-total"><i class="fa fa-check"></i><b>8.1.1</b> Partição da variabilidade total</a></li>
<li class="chapter" data-level="8.1.2" data-path="análise-de-variância-anova.html"><a href="análise-de-variância-anova.html#construção-do-teste-de-hipóteses"><i class="fa fa-check"></i><b>8.1.2</b> Construção do teste de hipóteses</a></li>
<li class="chapter" data-level="8.1.3" data-path="análise-de-variância-anova.html"><a href="análise-de-variância-anova.html#exemplo-19"><i class="fa fa-check"></i><b>8.1.3</b> Exemplo</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="análise-de-variância-anova.html"><a href="análise-de-variância-anova.html#anova-para-dois-fatores"><i class="fa fa-check"></i><b>8.2</b> ANOVA para dois fatores</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="análise-de-variância-anova.html"><a href="análise-de-variância-anova.html#partição-da-variabilidade-total-1"><i class="fa fa-check"></i><b>8.2.1</b> Partição da variabilidade total</a></li>
<li class="chapter" data-level="8.2.2" data-path="análise-de-variância-anova.html"><a href="análise-de-variância-anova.html#construção-do-teste-de-hipóteses-1"><i class="fa fa-check"></i><b>8.2.2</b> Construção do teste de hipóteses</a></li>
<li class="chapter" data-level="8.2.3" data-path="análise-de-variância-anova.html"><a href="análise-de-variância-anova.html#exemplo-continuação"><i class="fa fa-check"></i><b>8.2.3</b> Exemplo (continuação)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="regressão-linear.html"><a href="regressão-linear.html"><i class="fa fa-check"></i><b>9</b> Regressão Linear</a>
<ul>
<li class="chapter" data-level="9.1" data-path="regressão-linear.html"><a href="regressão-linear.html#gráficos-úteis"><i class="fa fa-check"></i><b>9.1</b> Gráficos úteis</a></li>
<li class="chapter" data-level="9.2" data-path="regressão-linear.html"><a href="regressão-linear.html#modelo-estatístico"><i class="fa fa-check"></i><b>9.2</b> Modelo estatístico</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="regressão-linear.html"><a href="regressão-linear.html#efeito-das-interações"><i class="fa fa-check"></i><b>9.2.1</b> Efeito das interações</a></li>
<li class="chapter" data-level="9.2.2" data-path="regressão-linear.html"><a href="regressão-linear.html#suposições-para-o-modelo"><i class="fa fa-check"></i><b>9.2.2</b> Suposições para o modelo</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="regressão-linear.html"><a href="regressão-linear.html#representação-matricial"><i class="fa fa-check"></i><b>9.3</b> Representação Matricial</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="regressão-linear.html"><a href="regressão-linear.html#estimação-dos-parâmetros-do-modelo"><i class="fa fa-check"></i><b>9.3.1</b> Estimação dos parâmetros do modelo</a></li>
<li class="chapter" data-level="9.3.2" data-path="regressão-linear.html"><a href="regressão-linear.html#propriedades-dos-estimadores-1"><i class="fa fa-check"></i><b>9.3.2</b> Propriedades dos estimadores</a></li>
<li class="chapter" data-level="9.3.3" data-path="regressão-linear.html"><a href="regressão-linear.html#exemplo-20"><i class="fa fa-check"></i><b>9.3.3</b> Exemplo</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="regressão-linear.html"><a href="regressão-linear.html#análise-de-variância-anova-1"><i class="fa fa-check"></i><b>9.4</b> Análise de Variância (ANOVA)</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="regressão-linear.html"><a href="regressão-linear.html#exemplo-continuação-1"><i class="fa fa-check"></i><b>9.4.1</b> Exemplo (continuação)</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="regressão-linear.html"><a href="regressão-linear.html#medidas-de-associação"><i class="fa fa-check"></i><b>9.5</b> Medidas de Associação</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="regressão-linear.html"><a href="regressão-linear.html#coeficiente-de-determinação-múltiplo-r2"><i class="fa fa-check"></i><b>9.5.1</b> Coeficiente de Determinação Múltiplo (<span class="math inline">\(R^2\)</span>)</a></li>
<li class="chapter" data-level="9.5.2" data-path="regressão-linear.html"><a href="regressão-linear.html#coeficiente-de-determinação-ajustado-r2_a"><i class="fa fa-check"></i><b>9.5.2</b> Coeficiente de Determinação Ajustado (<span class="math inline">\(R^2_a\)</span>)</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="regressão-linear.html"><a href="regressão-linear.html#testes-de-hipóteses-para-os-coeficientes-da-regressão"><i class="fa fa-check"></i><b>9.6</b> Testes de hipóteses para os coeficientes da regressão</a></li>
<li class="chapter" data-level="9.7" data-path="regressão-linear.html"><a href="regressão-linear.html#intervalo-de-confiança-para-os-coeficientes-da-regressão"><i class="fa fa-check"></i><b>9.7</b> Intervalo de confiança para os coeficientes da regressão</a></li>
<li class="chapter" data-level="9.8" data-path="regressão-linear.html"><a href="regressão-linear.html#seleção-de-variáveis-regressão-linear-múltipla"><i class="fa fa-check"></i><b>9.8</b> Seleção de Variáveis (Regressão Linear Múltipla)</a>
<ul>
<li class="chapter" data-level="9.8.1" data-path="regressão-linear.html"><a href="regressão-linear.html#seleção-de-todos-os-modelos-possíveis"><i class="fa fa-check"></i><b>9.8.1</b> Seleção de todos os modelos possíveis</a></li>
<li class="chapter" data-level="9.8.2" data-path="regressão-linear.html"><a href="regressão-linear.html#seleção-automática"><i class="fa fa-check"></i><b>9.8.2</b> Seleção automática</a></li>
</ul></li>
<li class="chapter" data-level="9.9" data-path="regressão-linear.html"><a href="regressão-linear.html#variáveis-dummy"><i class="fa fa-check"></i><b>9.9</b> Variáveis Dummy</a></li>
<li class="chapter" data-level="9.10" data-path="regressão-linear.html"><a href="regressão-linear.html#análise-de-resíduos"><i class="fa fa-check"></i><b>9.10</b> Análise de Resíduos</a>
<ul>
<li class="chapter" data-level="9.10.1" data-path="regressão-linear.html"><a href="regressão-linear.html#diagnóstico-de-normalidade"><i class="fa fa-check"></i><b>9.10.1</b> Diagnóstico de normalidade</a></li>
<li class="chapter" data-level="9.10.2" data-path="regressão-linear.html"><a href="regressão-linear.html#diagnóstico-de-homocedasticidade"><i class="fa fa-check"></i><b>9.10.2</b> Diagnóstico de homocedasticidade</a></li>
<li class="chapter" data-level="9.10.3" data-path="regressão-linear.html"><a href="regressão-linear.html#diagnóstico-de-independência"><i class="fa fa-check"></i><b>9.10.3</b> Diagnóstico de independência</a></li>
<li class="chapter" data-level="9.10.4" data-path="regressão-linear.html"><a href="regressão-linear.html#valores-extremos"><i class="fa fa-check"></i><b>9.10.4</b> Valores extremos</a></li>
<li class="chapter" data-level="9.10.5" data-path="regressão-linear.html"><a href="regressão-linear.html#teste-da-falta-de-ajuste-lack-of-fit"><i class="fa fa-check"></i><b>9.10.5</b> Teste da falta de ajuste (<em>lack of fit</em>)</a></li>
<li class="chapter" data-level="9.10.6" data-path="regressão-linear.html"><a href="regressão-linear.html#análise-de-colinearidade-e-multicolinearidade"><i class="fa fa-check"></i><b>9.10.6</b> Análise de Colinearidade e Multicolinearidade</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://paulamacaira.github.io/livro_inferencia_com_R" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Inferência Estatística com R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="teste-de-hipóteses" class="section level1" number="6">
<h1><span class="header-section-number">Capítulo 6</span> Teste de Hipóteses</h1>
<p>Vimos que é possível, através de estatísticas amostrais adequadas, estimar parâmetros de uma população, dentro de um certo intervalo de confiança. Nos testes de hipóteses, ao invés de se construir um intervalo de confiança no qual se espera que o parâmetro da população esteja contido, testa-se a validade de uma afirmação sobre um parâmetro da população. Então, num teste de hipóteses, procura-se tomar decisões a respeito de uma população, com base em informações obtidas de amostras desta mesma população.</p>
<div id="ideia-geral-1" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Ideia Geral</h2>
<p>O contexto em que se baseia a teoria de teste de hipóteses é basicamente o mesmo da teoria de estimação por intervalo de confiança. Temos uma população representada por uma variável aleatória <span class="math inline">\(X\)</span> cuja distribuição de probabilidade depende de algum parâmetro <span class="math inline">\(\theta\)</span>. O interesse agora está em testar a veracidade de alguma afirmativa sobre <span class="math inline">\(\theta\)</span>.</p>
<div id="hipótese-nula" class="section level3" number="6.1.1">
<h3><span class="header-section-number">6.1.1</span> Hipótese nula</h3>
<p>A hipótese nula, representada por <span class="math inline">\(H_0\)</span>, é a hipótese básica que queremos testar. Em geral, definimos a hipótese nula de modo que o nosso objetivo seja rejeitar <span class="math inline">\(H_0\)</span>. Nesse curso consideraremos apenas hipóteses nulas simples, isto é, hipóteses que estabelecem que o parâmetro de interesse é igual a um determinado valor. A forma geral é</p>
<p><span class="math display">\[H_0: \theta=\theta_0\]</span></p>
<p>Alguns exemplos são:</p>
<p><span class="math display">\[H_0: \mu=6 ~~~~~~ H_0: p=0.5 ~~~~~~ H_0: \sigma^2=25\]</span></p>
<p>O procedimento de teste de hipóteses resultará em uma <em>regra de decisão</em> que nos permitirá <em>rejeitar</em> ou <em>não rejeitar</em> <span class="math inline">\(H_0\)</span>.</p>
</div>
<div id="hipótese-alternativa" class="section level3" number="6.1.2">
<h3><span class="header-section-number">6.1.2</span> Hipótese alternativa</h3>
<p>A hipótese alternativa, representada por <span class="math inline">\(H_1\)</span>, é a hipótese que devemos considerar no caso de rejeição da hipótese nula. A forma mais geral de <span class="math inline">\(H_1\)</span> é a hipótese bilateral</p>
<p><span class="math display">\[H_1:\theta\ne\theta_0.\]</span></p>
<p>Porém, em algumas situações, podemos ter informação que nos permita restringir o domínio da hiótese alternativa. Temos, então, hipóteses unilaterais à esquerda</p>
<p><span class="math display">\[H_1:\theta&lt;\theta_0\]</span></p>
<p>e hipóteses unilaterais à direita</p>
<p><span class="math display">\[H_1:\theta&gt;\theta_0.\]</span></p>
<p>A escolha entre essas formas de hipótese alternativa se faz com base no conhecimento sobre o problema sendo considerado.</p>
</div>
<div id="estatística-de-teste" class="section level3" number="6.1.3">
<h3><span class="header-section-number">6.1.3</span> Estatística de teste</h3>
<p>Assim como na construção dos intervalos de confiança, iremos usar uma estatística amostral apropriada para construir o nosso teste de hipóteses e nesse contexto, essa estatística é chamada <em>estatística de teste</em>. As estatísticas de teste usuais são a média amostral <span class="math inline">\(\bar X\)</span> e a proporção amostral <span class="math inline">\(\hat P\)</span>, que serão usadas na construção de testes sobre a média e a proporção populacionais, respectivamente.</p>
</div>
<div id="tipos-de-erro" class="section level3" number="6.1.4">
<h3><span class="header-section-number">6.1.4</span> Tipos de erro</h3>
<p>O procedimento de decisão é definido em termos da hipótese nula <span class="math inline">\(H_0\)</span> e as decisões possíveis são (i) rejeitar ou (ii) não rejeitar <span class="math inline">\(H_0\)</span>. Existem duas possibilidades de erro:</p>
<ul>
<li>Erro tipo I: rejeitar <span class="math inline">\(H_0\)</span> quando <span class="math inline">\(H_0\)</span> é verdadeira</li>
<li>Erro tipo II: não rejeitar <span class="math inline">\(H_0\)</span> quando <span class="math inline">\(H_0\)</span> é falsa</li>
</ul>
</div>
<div id="regra-de-decisão" class="section level3" number="6.1.5">
<h3><span class="header-section-number">6.1.5</span> Regra de decisão</h3>
<p>A decisão sobre a hipótese nula é tomada com base em uma regra que estabelece um conjunto de valores, chamado <em>região crítica</em> (RC) ou <em>região de rejeição</em>, de modo que se, o valor observado da estatística amostral cair nesse região, rejeitaremos <span class="math inline">\(H_0\)</span>; caso contrário, não rejeitaremos <span class="math inline">\(H_0\)</span>.</p>
</div>
<div id="região-crítica" class="section level3" number="6.1.6">
<h3><span class="header-section-number">6.1.6</span> Região crítica</h3>
<p>Em geral, a definição da região crítica é feita da seguinte forma: RC é o conjunto de valores cuja probabilidade de ocorrência é pequena sob a hipótese de veracidade de <span class="math inline">\(H_0\)</span>.</p>
<p>A definição de “probabilidade pequena” se faz através da escolha do <strong>nível de significância</strong> <span class="math inline">\(\alpha\)</span> do teste, que é a <strong>probabilidade do erro tipo I</strong>, isto é,</p>
<p><span class="math display">\[\alpha=P(\text{erro tipo I})=P(\text{rejeitar } H_0 | H_0 \text{ verdadeira})\]</span></p>
<p>Em geral, o valor de <span class="math inline">\(\alpha\)</span> é pequeno e as escolhas mais comuns são <span class="math inline">\(\alpha=0.05\)</span> e <span class="math inline">\(\alpha=0.01\)</span>.</p>
<p>Definido o nível de significância <span class="math inline">\(\alpha\)</span>, podemos estabelecer a região crítica usando a distribuição amostral da estatística de teste.</p>
</div>
<div id="cco-e-poder-do-teste" class="section level3" number="6.1.7">
<h3><span class="header-section-number">6.1.7</span> CCO e Poder do Teste</h3>
<p>No procedimento de teste de hipóteses, as decisões possíveis são rejeitar ou não rejeitar <span class="math inline">\(H_0\)</span>. Definem-se, assim, as seguintes funções em termos das probabilidades de cada uma delas. A <em>Curva Característica da Operação</em> (CCO) é definida como</p>
<p><span class="math display">\[\beta(\theta)=P(\text{não rejeitar } H_0|\theta)\]</span></p>
<p>Define-se a <em>função Poder de Teste</em> como</p>
<p><span class="math display">\[Q(\theta)=1-\beta(\theta)=P(\text{rejeitar } H_0|\theta)\]</span></p>
<p>Estas funções (probabilidades) estão condicionadas ao verdadeiro e desconhecido valor do parâmetro <span class="math inline">\(\theta\)</span>. Se este valor estiver no conjunto de valores definidos pela hipótese alternativa, então <span class="math inline">\(Q(\theta)\)</span> corresponde a uma probabilidade de <strong>acerto</strong>: ela mede a probabilidade de se rejeitar <span class="math inline">\(H_0\)</span> quando <span class="math inline">\(H_0\)</span> é falsa. Por outro lado, se a hipótese nula é <span class="math inline">\(H_0: \theta=\theta_0\)</span>, então</p>
<ul>
<li><span class="math inline">\(Q(\theta_0)=1-\beta(\theta_0)\)</span></li>
<li><span class="math inline">\(Q(\theta_0)=1-P(\text{não rejeitar } H_0|\theta)\)</span></li>
<li><span class="math inline">\(Q(\theta_0)=1-P(\text{não rejeitar } H_0|H_0 \text{ verdadeira})\)</span></li>
<li><span class="math inline">\(Q(\theta_0)=P(\text{rejeitar } H_0|H_0 \text{ verdadeira})\)</span></li>
<li><span class="math inline">\(Q(\theta_0)=\alpha\)</span></li>
</ul>
</div>
<div id="exemplo" class="section level3" number="6.1.8">
<h3><span class="header-section-number">6.1.8</span> Exemplo</h3>
<p>Consideremos uma população representada por uma variável aleatória normal com média <span class="math inline">\(\mu\)</span> e variância 400. Deseja-se testar:</p>
<p><span class="math display">\[H_0:\mu=100~~~\text{vs}~~~H_1: \mu \ne 100\]</span></p>
<p>com base em uma amostra aleatória simples de tamanho <span class="math inline">\(n=16\)</span>. Para tal, define-se a seguinte região crítica:</p>
<p><span class="math display">\[RC: \bar X &lt; 85\text{ ou }\bar X &gt; 115\]</span></p>
<ol style="list-style-type: decimal">
<li>Calcule a probabilidade do erro tipo I</li>
<li>Calcule a função poder do teste para os seguintes valores de <span class="math inline">\(\mu: 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, 125\)</span></li>
</ol>
<p><strong>Solução</strong></p>
<p>Como queremos fazer um teste sobre a média da população, é natural usarmos <span class="math inline">\(\bar X\)</span> como estatística de teste. Como a população é normal com média <span class="math inline">\(\mu\)</span> e variância 400, sabemos que <span class="math inline">\(\bar X\sim N(\mu,\frac{400}{16}=25)\)</span></p>
<ol style="list-style-type: decimal">
<li>Sob a hipótese nula, <span class="math inline">\(\mu=100\)</span>. Então,</li>
</ol>
<ul>
<li><span class="math inline">\(\alpha = P(\text{rejeitar } H_0 | H_0 \text{ verdadeira}\rightarrow \mu=100)\)</span></li>
<li><span class="math inline">\(\alpha = P\Big(\{\bar X&lt;85\} \cup \{\bar X&gt;115\}|\bar X\sim N(100,25)\Big)\)</span></li>
<li><span class="math inline">\(\alpha = P\Big(\bar X&lt;85 |\bar X\sim N(\mu,25)\Big) + P\Big(\bar X&gt;115 |\bar X\sim N(\mu,25)\Big)\)</span></li>
<li><span class="math inline">\(\alpha = P\Big(Z&lt;\frac{85-100}{5}\Big) + P\Big(Z&gt;\frac{115-100}{5}\Big)\)</span></li>
<li><span class="math inline">\(\alpha = P\Big(Z&lt;-3\Big) + P\Big(Z&gt;3\Big)\)</span></li>
<li><span class="math inline">\(\alpha = 2\times P\Big(Z&gt;3\Big)\)</span></li>
<li><span class="math inline">\(\alpha = 0.0027\)</span></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>A função poder do teste é dada por:</li>
</ol>
<ul>
<li><span class="math inline">\(Q(\mu) = 1-\beta(\mu)\)</span></li>
<li><span class="math inline">\(Q(\mu)=1-P(\text{não rejeitar } H_0|\mu)\)</span></li>
<li><span class="math inline">\(Q(\mu)=1-P(85&lt;\bar X&lt;115|\mu)\)</span></li>
<li><span class="math inline">\(Q(\mu)=1-P(85&lt;\bar X&lt;115|\bar X\sim N(\mu,25))\)</span></li>
<li><span class="math inline">\(Q(\mu)=1-P(\frac{85-\mu}{5}&lt; Z&lt;\frac{115-\mu}{5}|\bar X\sim N(\mu,25))\)</span></li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:right;">
Mu
</th>
<th style="text-align:right;">
Q(mu)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
75
</td>
<td style="text-align:right;">
0.97725
</td>
</tr>
<tr>
<td style="text-align:right;">
80
</td>
<td style="text-align:right;">
0.84134
</td>
</tr>
<tr>
<td style="text-align:right;">
85
</td>
<td style="text-align:right;">
0.50000
</td>
</tr>
<tr>
<td style="text-align:right;">
90
</td>
<td style="text-align:right;">
0.15866
</td>
</tr>
<tr>
<td style="text-align:right;">
95
</td>
<td style="text-align:right;">
0.02278
</td>
</tr>
<tr>
<td style="text-align:right;">
100
</td>
<td style="text-align:right;">
0.00270
</td>
</tr>
<tr>
<td style="text-align:right;">
105
</td>
<td style="text-align:right;">
0.02278
</td>
</tr>
<tr>
<td style="text-align:right;">
110
</td>
<td style="text-align:right;">
0.15866
</td>
</tr>
<tr>
<td style="text-align:right;">
115
</td>
<td style="text-align:right;">
0.50000
</td>
</tr>
<tr>
<td style="text-align:right;">
120
</td>
<td style="text-align:right;">
0.84134
</td>
</tr>
<tr>
<td style="text-align:right;">
125
</td>
<td style="text-align:right;">
0.97725
</td>
</tr>
</tbody>
</table>
<p><img src="inferencia_com_R_files/figure-html/unnamed-chunk-66-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Observe que, para <span class="math inline">\(\mu=100\)</span>, valor da hipótese nula, a função poder é igual à probabilidade do erro tipo I (nível de significância).</p>
<p>É interessante notar também que quanto mais distante do valor <span class="math inline">\(\mu_0=100\)</span>, maior o poder do teste, ou seja, há uma probabilidade mais alta de se rejeitar <span class="math inline">\(H_0\)</span> quando o valor alternativo <span class="math inline">\(\mu\)</span> está bem distante de <span class="math inline">\(\mu_0\)</span>.</p>
<p>Agora, considere a situação do exemplo anterior, com as seguintes diferenças: o tamanho da amostra é <span class="math inline">\(n=100\)</span> e a região crítica passa a ser</p>
<p><span class="math display">\[RC: \bar X &lt; 94\text{ ou }\bar X &gt; 106\]</span></p>
<p>Note que é razoável “estreitar” a região crítica, já que a amostra é maior. Nesse caso, <span class="math inline">\(\alpha\)</span> é exatamente igual ao do exemplo anterior, já a função poder do teste para os mesmos valores (em vermelho <span class="math inline">\(n=100\)</span>):</p>
<p><img src="inferencia_com_R_files/figure-html/unnamed-chunk-67-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Note que o poder do teste baseado em uma amostra de tamanho 100 é sempre maior que o poder do teste baseado em uma amostra de tamanho 16.</p>
</div>
</div>
<div id="t.h.-para-a-média-de-uma-normal-com-variância-conhecida" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> T.H. para a média de uma Normal com variância conhecida</h2>
<p>Neste capítulo iremos aplicar os conceitos básicos sobre a teoria de teste de hipóteses a uma situação específica. Nosso interesse estará concentrado na média de uma população normal. Assim como no caso dos intervalos de confiança, iremos iniciar nossos estudos supondo que a variância dessa população seja conhecida. Como já dito, essa situação não é muito comum na prática, mas, em termos didáticos, a apresentação dos conceitos fica simplificada. Entendendo bem a construção de um teste de hipóteses para esse caso particular, a apresentação para as outras situações é bastante semelhante, mudando apenas a distribuição amostral.</p>
<p><strong>Contextualizando com um exemplo</strong></p>
<p>Depois de uma pane geral no sistema de informação de uma empresa, o gerente administrativo deseja saber se houve alteração no tempo de processamento de determinada atividade. Antes da pane, o tempo de processamento podia ser aproximado por uma variável aleatória normal com média de 100 minutos e desvio padrão de 10 minutos. O gerente acredita que a pane não tenha alterado a variabilidade do processo. Uma amostra de 16 tempos de processamento após a pane revela uma média de 105,5 minutos. Ao nível de significância de 5%, qual é a conclusão sobre a alteração do tempo médio de processamento?</p>
<p><strong>Solução</strong></p>
<p>O interesse do gerente é comparar os tempos antes e depois da pane. Antes da pane, o tempo médio de processamento era de 100 minutos. Como ele não sabe o tipo de alteração que possa ter ocorrido, ele precisa saber se o tempo médio depois da pane é diferente do tempo anterior. Isso nos leva às seguintes hipóteses nula e alternativa:</p>
<p><span class="math display">\[H_0:\mu=100\text{  vs  } H_1:\mu\neq 100\]</span></p>
<p>Seja <span class="math inline">\(X\)</span> a variável aleatória que representa o tempo de processamento. Então, pelos dados do problema, temos que <span class="math inline">\(X\sim N(\mu; 100)\)</span>. Antes da pane, <span class="math inline">\(\mu =100\)</span>. Como a população é normal, sabemos que a distribuição da média amostral também é normal e como não deve ter havido alteração na variabilidade do processo, resulta que o desvio padrão é de 10 minutos em qualquer situação. Logo,</p>
<p><span class="math display">\[\bar X \sim N\left(\mu,\frac{100}{16}\right)\]</span></p>
<p>ou equivalentemente,</p>
<p><span class="math display">\[Z=\frac{\bar X-\mu}{2,5}\sim N(0,1)\]</span></p>
<p>Pelo enunciado do problema, o nível de significância é de 5%. Isso significa que a probabilidade do erro tipo I é 0,05. Como visto, o erro tipo I consiste em rejeitar a hipótese nula quando ela é verdadeira. Logo,</p>
<p><span class="math display">\[\alpha=P(\text{rejeitar }H_0|H_0\text{ verdadeira})=0,05\]</span></p>
<p>Quando <span class="math inline">\(H_0\)</span> verdadeira, a estatística de teste tem a seguinte distribuição:</p>
<p><span class="math display">\[H_0\text{ verdadeira} \Rightarrow \bar X \sim N\left(100,\frac{100}{16}\right)\]</span></p>
<p>ou equivalentemente,</p>
<p><span class="math display">\[Z=\frac{\bar X-100}{\sqrt{\frac{100}{16}}}\sim N(0,1)\]</span></p>
<p>A nossa região crítica consiste nos valores de <span class="math inline">\(X\)</span> com probabilidade pequena de ocorrerem sob essa hipótese. Ou seja, a região crítica consiste nos valores de <span class="math inline">\(X\)</span> muito afastados da média suposta de <span class="math inline">\(\mu=100\)</span>. Como a hipótese alternativa é bilateral, “muito afastado” significa “muito maior” ou “muito menor” do que <span class="math inline">\(\mu=100\)</span>.</p>
<p><img src="inferencia_com_R_files/figure-html/unnamed-chunk-68-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Então, nossa região crítica é</p>
<p><span class="math display">\[\bar X &lt; 100-k \text{  ou  } \bar X  &gt; 100+k\]</span></p>
<p>e isso é equivalente a</p>
<p><span class="math display">\[\bar X -100 &lt; -k \text{  ou  } \bar X -100 &gt; +k\]</span></p>
<p>Usando a função módulo, podemos escrever:</p>
<p><span class="math display">\[RC: |\bar X -100|&gt;k\]</span></p>
<p>e o valor da constante <span class="math inline">\(k\)</span> é determinado pelo nível de significância:</p>
<p><span class="math inline">\(P\left[|\bar X -100|&gt;k\Big|\bar X \sim N\left(100;6,25\right)\right] = 0,05\)</span></p>
<p><span class="math inline">\(P\left(\bar X &lt; 100-k|\bar X \sim N(100,6,25)\right)+P\left(\bar X &gt; 100+k|\bar X \sim N(100,6,25)\right) = 0,05\)</span></p>
<p><span class="math inline">\(P\left(Z&lt;\frac{-k}{2,5}\right)+P\left(Z&gt;\frac{k}{2,5}\right) = 0,05\)</span></p>
<p><span class="math inline">\(P\left(Z&gt;\frac{k}{2,5}\right)+P\left(Z&gt;\frac{k}{2,5}\right) = 0,05\)</span></p>
<p><span class="math inline">\(P\left(Z&gt;\frac{k}{2,5}\right) = 0,025\)</span></p>
<p>Como, <span class="math inline">\(z_{0,025}=1.96\)</span>, então <span class="math inline">\(\frac{k}{2,5}=1,96\)</span>, assim <span class="math inline">\(k=4,9\)</span>.</p>
<p>A região crítica é</p>
<p><span class="math display">\[RC: \bar X&lt;95,1\text{  ou  }\bar X&gt;104,9\]</span></p>
<p>Como o valor da estatística de teste para a amostra observada está na região crítica, devemos rejeitar a hipótese nula, ou seja, as evidências amostrais indicam uma alteração do tempo de processamento da tarefa após a pane.</p>
<p>A função poder do teste é definida como</p>
<p><span class="math display">\[\beta(\mu)=P(\text{rejeitar } H_0|\mu)\]</span></p>
<p>Em termos da nossa região crítica podemos escrever</p>
<p><span class="math display">\[
\begin{aligned}
\beta(\mu)&amp;= P\left[\bar X&lt;95,1 |\bar X \sim N(100,6,25)\right] + P\left[\bar X&gt;104,9 |\bar X \sim N(100,6,25)\right] \\
&amp;=P\left[Z&lt;\frac{95,1-\mu}{2,5}\right]+P\left[Z&gt;\frac{104,9-\mu}{2,5}\right]
\end{aligned}
\]</span></p>
<p>Calculando <span class="math inline">\(\beta(\mu)\)</span> para diferentes valores de <span class="math inline">\(\mu\)</span> obtemos o gráfico exibido na Figura abaixo:</p>
<p><img src="inferencia_com_R_files/figure-html/unnamed-chunk-69-1.png" width="576" style="display: block; margin: auto;" /></p>
<div id="construindo-o-teste-de-hipóteses" class="section level3" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Construindo o teste de hipóteses</h3>
<p>De posse de uma amostra aleatória simples <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> extraída de uma população <span class="math inline">\(X\sim N(\mu; \sigma^2)\)</span>, nosso interesse está em testar a hipótese nula</p>
<p><span class="math display">\[H_0: \mu = \mu_0\]</span></p>
<p>a um nível de significância <span class="math inline">\(\alpha\)</span>.</p>
<p>Dependendo do conhecimento sobre o problema, a hipótese alternativa pode tomar uma das três formas:</p>
<p><span class="math display">\[H_1:\mu\neq\mu_0~~~~~~H_1:\mu&gt;\mu_0~~~~~~H_1:\mu&lt;\mu_0\]</span></p>
<p>Em qualquer dos casos, a estatística de teste é a média amostral; se a variância <span class="math inline">\(\sigma^2\)</span> é conhecida, sabemos que</p>
<p><span class="math display">\[\bar X \sim N\left(\mu,\frac{\sigma^2}{n}\right)\]</span></p>
<p>A regra de decisão consiste em rejeitar a hipótese nula se o valor de <span class="math inline">\(\bar X\)</span> estiver “longe” do valor <span class="math inline">\(\mu_0\)</span>. No caso da hipótese alternativa bilateral, estar longe significa ser muito maior ou muito menor que <span class="math inline">\(\mu_0\)</span>; para a alternativa unilateral à direita, estar longe significa ser muito maior do que <span class="math inline">\(\mu_0\)</span> e para a alternativa unilateral à esquerda, longe significa ser muito menor que <span class="math inline">\(\mu_0\)</span>. As expressões “muito menor” e “muito maior” ficam perfeitamente definidas a partir do valor do nível de significância <span class="math inline">\(\alpha\)</span>.</p>
<p>Veja as Figuras abaixo, em que ilustra-se a região crítica para as três hipóteses alternativas. Como antes, vamos denotar por <span class="math inline">\(z_\alpha\)</span> a abscissa da curva normal padrão que deixa área (probabilidade) <span class="math inline">\(\alpha\)</span> acima dela.</p>
<p><img src="inferencia_com_R_files/figure-html/unnamed-chunk-70-1.png" width="576" style="display: block; margin: auto;" /></p>
<p><img src="inferencia_com_R_files/figure-html/unnamed-chunk-71-1.png" width="576" style="display: block; margin: auto;" /></p>
<p><img src="inferencia_com_R_files/figure-html/unnamed-chunk-72-1.png" width="576" style="display: block; margin: auto;" /></p>
<div id="bilateral" class="section level4" number="6.2.1.1">
<h4><span class="header-section-number">6.2.1.1</span> Bilateral</h4>
<p>Consideremos as hipóteses</p>
<p><span class="math display">\[H_0:\mu=\mu_0 \text{  vs  } H_1:\mu\ne\mu_0\]</span></p>
<p>A região crítica é</p>
<p><span class="math display">\[\bar X &lt; \mu_0-k\text{ ou }\bar X &gt; \mu_0+k\]</span></p>
<p>e se a hipótese nula é verdadeira,</p>
<p><span class="math display">\[\bar X \sim N\left(\mu_0,\frac{\sigma^2}{n}\right)\]</span></p>
<p>Com nível de significância <span class="math inline">\(\alpha=P(\text{erro tipo I})\)</span>, temos que ter:</p>
<p><span class="math inline">\(\alpha=P\left(\text{rejeitar }H_0|H_0\text{ verdadeira}\right)\)</span></p>
<p><span class="math inline">\(\alpha=P\left(\bar X &lt; \mu_0-k\text{ ou }\bar X &gt; \mu_0+k|\bar X \sim N\left(\mu_0,\frac{\sigma^2}{n}\right)\right)\)</span></p>
<p><span class="math inline">\(\alpha=P\left(\bar X &lt; \mu_0-k|\bar X \sim N\left(\mu_0,\frac{\sigma^2}{n}\right)\right) + P\left(\bar X &gt; \mu_0+k|\bar X \sim N\left(\mu_0,\frac{\sigma^2}{n}\right)\right)\)</span></p>
<p><span class="math inline">\(\alpha=P\left(Z&lt;\frac{-k}{\frac{\sigma}{\sqrt n}}\right)+P\left(Z&gt;\frac{k}{\frac{\sigma}{\sqrt n}}\right)\)</span></p>
<p><span class="math inline">\(\alpha=2\times P\left(Z&gt;\frac{k}{\frac{\sigma}{\sqrt n}}\right)\)</span></p>
<p><span class="math inline">\(\frac{\alpha}{2}=P\left(Z&gt;\frac{k}{\frac{\sigma}{\sqrt n}}\right)\)</span></p>
<p><span class="math inline">\(\frac{k}{\frac{\sigma}{\sqrt n}}=z_{\frac{\alpha}{2}}\)</span></p>
<p><span class="math inline">\(k = z_{\frac{\alpha}{2}}\frac{\sigma}{\sqrt n}\)</span></p>
<p>Logo, a região crítica é:</p>
<p><span class="math display">\[\bar X &lt; \mu_0-z_{\frac{\alpha}{2}}\frac{\sigma}{\sqrt n}\text{ ou }\bar X &gt; \mu_0+z_{\frac{\alpha}{2}}\frac{\sigma}{\sqrt n}\]</span></p>
</div>
<div id="unilateral-à-direita" class="section level4" number="6.2.1.2">
<h4><span class="header-section-number">6.2.1.2</span> Unilateral à direita</h4>
<p>Consideremos as hipóteses</p>
<p><span class="math display">\[H_0:\mu=\mu_0 \text{  vs  } H_1:\mu&gt;\mu_0\]</span></p>
<p>A região crítica é</p>
<p><span class="math display">\[\bar X &gt; \mu_0+k\]</span></p>
<p>e se a hipótese nula é verdadeira,</p>
<p><span class="math display">\[\bar X \sim N\left(\mu_0,\frac{\sigma^2}{n}\right)\]</span></p>
<p>Com nível de significância <span class="math inline">\(\alpha=P(\text{erro tipo I})\)</span>, temos que ter:</p>
<p><span class="math inline">\(\alpha=P\left(\text{rejeitar }H_0|H_0\text{ verdadeira}\right)\)</span></p>
<p><span class="math inline">\(\alpha=P\left(\bar X &gt; \mu_0+k|\bar X \sim N\left(\mu_0,\frac{\sigma^2}{n}\right)\right)\)</span></p>
<p><span class="math inline">\(\alpha=P\left(Z&gt;\frac{k}{\frac{\sigma}{\sqrt n}}\right)\)</span></p>
<p><span class="math inline">\(\frac{k}{\frac{\sigma}{\sqrt n}}=z_{\alpha}\)</span></p>
<p><span class="math inline">\(k = z_{\alpha}\frac{\sigma}{\sqrt n}\)</span></p>
<p>Logo, a região crítica é:</p>
<p><span class="math display">\[\bar X &gt; \mu_0+z_{\alpha}\frac{\sigma}{\sqrt n}\]</span></p>
</div>
<div id="unilateral-à-esquerda" class="section level4" number="6.2.1.3">
<h4><span class="header-section-number">6.2.1.3</span> Unilateral à esquerda</h4>
<p>Consideremos as hipóteses</p>
<p><span class="math display">\[H_0:\mu=\mu_0 \text{  vs  } H_1:\mu&lt;\mu_0\]</span></p>
<p>A região crítica é</p>
<p><span class="math display">\[\bar X &lt; \mu_0-k\]</span></p>
<p>e se a hipótese nula é verdadeira,</p>
<p><span class="math display">\[\bar X \sim N\left(\mu_0,\frac{\sigma^2}{n}\right)\]</span></p>
<p>Com nível de significância <span class="math inline">\(\alpha=P(\text{erro tipo I})\)</span>, temos que ter:</p>
<p><span class="math inline">\(\alpha=P\left(\text{rejeitar }H_0|H_0\text{ verdadeira}\right)\)</span></p>
<p><span class="math inline">\(\alpha=P\left(\bar X &lt; \mu_0-k|\bar X \sim N\left(\mu_0,\frac{\sigma^2}{n}\right)\right)\)</span></p>
<p><span class="math inline">\(\alpha=P\left(Z&lt;-\frac{k}{\frac{\sigma}{\sqrt n}}\right)\)</span></p>
<p><span class="math inline">\(\alpha=P\left(Z&gt;\frac{k}{\frac{\sigma}{\sqrt n}}\right)\)</span></p>
<p><span class="math inline">\(\frac{k}{\frac{\sigma}{\sqrt n}}=z_{\alpha}\)</span></p>
<p><span class="math inline">\(k = z_{\alpha}\frac{\sigma}{\sqrt n}\)</span></p>
<p>Logo, a região crítica é:</p>
<p><span class="math display">\[\bar X &lt; \mu_0-z_{\alpha}\frac{\sigma}{\sqrt n}\]</span></p>
</div>
</div>
<div id="teste-de-hipóteses-vs-intervalo-de-confiança" class="section level3" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> Teste de Hipóteses vs Intervalo de Confiança</h3>
<p>É interessante notar a expressão que aparece na região crítica para o teste bilateral; ela é a mesma obtida para a margem de erro do intervalo de confiança para a média de uma população normal com variância conhecida:</p>
<p><span class="math display">\[\varepsilon=z_{\frac{\alpha}{2}}\frac{\sigma}{\sqrt n}\]</span></p>
<p>Podemos ver, assim, que existe uma relação entre os dois procedimentos; na verdade, em um teste de hipóteses bilateral, rejeitamos a hipótese nula <span class="math inline">\(H_0\)</span> se o valor observado da estatística de teste não estiver no intervalo de confiança.</p>
</div>
<div id="valor-p-ou-p-valor" class="section level3" number="6.2.3">
<h3><span class="header-section-number">6.2.3</span> Valor P (ou p-valor)</h3>
<p>Nos exemplos acima, a determinação da região crítica foi feita com base no nível de significância, isto é, fixado o nível de significância encontramos o valor <span class="math inline">\(k\)</span> que definia os limites entre valores prováveis (aqueles que levam à não rejeição de <span class="math inline">\(H_0\)</span>) e pouco prováveis (aqueles que levam à rejeição de <span class="math inline">\(H_0\)</span>). Um outro procedimento bastante usual, especialmente quando são utilizados programas computacionais, consiste em calcular a probabilidade de se obter um valor tão ou mais desfavorável que o valor observado, se <span class="math inline">\(H_0\)</span> for verdadeira. Essa probabilidade é chamada valor P ou p-valor.</p>
<p>Portanto, definimos p-valor como: a probabilidade de obtermos um valor tão ou mais extremo que o valor observado dado que <span class="math inline">\(H_0\)</span> é verdadeira. Devemos rejeitar a hipótese nula <span class="math inline">\(H_0\)</span> ao nível de significância <span class="math inline">\(\alpha\)</span> sempre que o p-valor for menor ou igual a <span class="math inline">\(\alpha\)</span>,ou seja:</p>
<p><span class="math display">\[\text{Rejeitamos } H_0\Leftrightarrow \text{p-valor} \leq \alpha\]</span></p>
</div>
<div id="exemplo-3" class="section level3" number="6.2.4">
<h3><span class="header-section-number">6.2.4</span> Exemplo</h3>
<p><strong>Solução</strong></p>
<p>No exemplo exposto no início da seção, o valor obtido com os dados amostrais para a estatística de teste foi <span class="math inline">\(\bar x = 105,5\)</span>. Como o teste é bilateral, valores “longe” de 100 são aqueles muito menores ou muito maiores que 100. O procedimento visto consistiu em dividir a probabilidade do erro tipo I igualmente nas duas caudas da distribuição normal e dessa forma identificamos a região crítica. Vamos, agora, calcular o valor P para o nosso exemplo; ele é a probabilidade de obtermos um valor tão ou mais extremo que o valor observado. Como o valor observado está à direita da média, devemos calcular a seguinte probabilidade:</p>
<p><span class="math display">\[
\begin{aligned}
P &amp;= P\left(\bar X \geq 105,5|H_0\text{ verdadeira}\right)\\
&amp;= P\left[\bar X \geq 105,5|\bar X \sim N\left(100;\frac{100}{16}\right)\right]\\
&amp;=P\left(Z\geq \frac{105,5-100}{2,5}\right)\\
&amp;=P(Z\geq 2,2)\\
&amp;=0,0139
\end{aligned}
\]</span></p>
<p>Vamos analisar a Figura abaixo, onde está ilustrado esse valor. O valor amostral observado para <span class="math inline">\(\bar X\)</span> é <span class="math inline">\(\bar x = 105,5 = 100+5,5\)</span>. Como o teste é bilateral, se tivéssemos obtido o valor <span class="math inline">\(\bar x = 100 - 5,5\)</span>, esse valor também seria considerado tão afastado de <span class="math inline">\(100\)</span> quanto <span class="math inline">\(105,5\)</span>. Assim, para testes bilaterais, temos que considerar a probabilidade nas duas caudas da distribuição. O que esse resultado está nos dizendo é o seguinte: se <span class="math inline">\(H_0\)</span> for verdadeira, a probabilidade de obtermos um valor distante de <span class="math inline">\(100\)</span> por <span class="math inline">\(5,5\)</span> unidades em qualquer direção é <span class="math inline">\(2\times 0,0139 = 0,0278\)</span>. Essa probabilidade é chamada valor P.</p>
<p><img src="inferencia_com_R_files/figure-html/unnamed-chunk-73-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>No exemplo, vemos que o valor P é pequeno, o que significa que é pouco provável obtermos um valor tão extremo quando <span class="math inline">\(H_0\)</span> é verdadeira. Logo, é razoável supormos que a hipótese nula não seja verdadeira, a mesma conclusão obtida ao trabalharmos com o nível de significância de 5%. Na verdade, rejeitaríamos a hipótese nula para qualquer nível de significância maior que <span class="math inline">\(0,0278\)</span>.</p>
</div>
</div>
<div id="t.h.-para-a-média-de-uma-normal-com-variância-desconhecida" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> T.H. para a média de uma Normal com variância desconhecida</h2>
<p>Neste capítulo você completará seu estudo básico de testes de hipóteses sobre a média de uma população, analisando a situação relativa a uma população normal quando não se conhece a variância desta população. Assim como no caso do intervalo de confiança, para testar hipóteses relativas à média de tal população, é necessário estimar essa variância e isso introduz mais uma fonte de variabilidade no procedimento: com uma única amostra, queremos testar hipóteses sobre a média, mas precisamos também estimar a variância da população. O procedimento é simples e análogo aos casos estudados nos caítulos anteriores; o que muda é a distribuição amostral da estatística de teste. Em vez de usarmos a distribuição normal para determinar os valores críticos, usaremos novamente a distribuição t de Student.</p>
<p>Considere uma população descrita por uma variável aleatória normal com média <span class="math inline">\(\mu\)</span> e variância <span class="math inline">\(\sigma^2\)</span>: <span class="math inline">\(X\sim N(\mu,\sigma^2)\)</span>. Nosso interesse é testar hipóteses sobre a média <span class="math inline">\(\mu\)</span> a partir de uma amostra aleatória simples <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span>. Como visto anteriormente, se a variância <span class="math inline">\(\sigma^2\)</span> não é conhecida, então temos que usar a estatística</p>
<p><span class="math display">\[T=\sqrt{n}\frac{\bar X-\mu}{S}\]</span></p>
<p>cuja distribuição <span class="math inline">\(t\)</span> de Student com <span class="math inline">\(n-1\)</span> graus de liberdade.</p>
<div id="construindo-o-teste-de-hipóteses-1" class="section level3" number="6.3.1">
<h3><span class="header-section-number">6.3.1</span> Construindo o teste de hipóteses</h3>
<p>De posse desta estatística de teste, o procedimento de construção do teste é idêntico ao visto anteriormente: identificadas a hipótese nula (sempre na forma de uma hipótese simples <span class="math inline">\(\mu=\mu_0\)</span>) e a hipótese alternativa, a região crítica é formada pelos valores da estatística de teste pouco prováveis sob <span class="math inline">\(H_0\)</span>. O nível de significância e o tipo de hipótese alternativa permitem a identificação precisa do que são “valores pouco prováveis”: são valores na(s) cauda(s) da distribuição de <span class="math inline">\(T\)</span> quando a hipótese nula é verdadeira.</p>
<p>Seja <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span> uma amostra amostra aleatória simples de uma população <span class="math inline">\(X\)</span> cuja disribuição é <span class="math inline">\(N(\mu; \sigma^2)\)</span>. Nosso interesse é testar alguma hipótese sobre a média <span class="math inline">\(\mu\)</span> desta população. Em geral, a variância <span class="math inline">\(\sigma^2\)</span> não é conhecida e, portanto, vamos estimá-la por</p>
<p><span class="math display">\[S^2=\frac{1}{n-1}\sum_{i=1}^n \left(X_i-\bar X\right)^2\]</span></p>
<p>Lembre-se que <span class="math inline">\(S^2\)</span> é um estimador não-viesado de <span class="math inline">\(\sigma^2\)</span>.</p>
<p>A hipótese nula que iremos considerar será</p>
<p><span class="math display">\[H_0:\mu=\mu_0\]</span></p>
<p>As possíveis formas da hipótese alternativa são:</p>
<ul>
<li>Bilateral: <span class="math inline">\(H_1:\mu\ne\mu_0\)</span></li>
<li>Unilateral à direita: <span class="math inline">\(H_1:\mu &gt; \mu_0\)</span></li>
<li>Unilateral à esuqerda: <span class="math inline">\(H_1:\mu &lt; \mu_0\)</span></li>
</ul>
<p>Como antes, a escolha entre essas três possibilidades se faz com base no conhecimento do problema. Se não temos informação alguma sobre a alternativa, temos que usar um teste bilateral.</p>
<p>Como o teste é sobre a média de uma população normal, a estatística amostral que deve ser utilizada é <span class="math inline">\(\bar X\)</span>. Como a variância populacional não é conhecida, sabemos que</p>
<p><span class="math display">\[T=\frac{\bar X-\mu}{\frac{S}{\sqrt n}} \sim t(n-1)\]</span></p>
<p>e é a nossa estatística de teste.</p>
<p>A regra de decisão consiste em definir a região crítica RC como o conjunto de valores cuja probabilidade de ocorrência é pequena sob a hipótese de veracidade de <span class="math inline">\(H_0\)</span>. Logo, nossa regra de decisão se baseia na estatística de teste</p>
<p><span class="math display">\[T_0=\frac{\bar X-\mu_0}{\frac{S}{\sqrt n}} \sim t(n-1)\]</span></p>
<p>Como a estatística de teste segue uma distribuição t de Student, valores com pequena probabilidade de ocorrência estão nas caudas da distribuição. Isso equivale a valores de <span class="math inline">\(\bar X\)</span> “distandes” de <span class="math inline">\(\mu_0\)</span>. Assim, a região crítica para cada tipo de hipótese alternativa é definida como segue:</p>
<ul>
<li>Bilateral: <span class="math inline">\(T_0 &lt; -k\)</span> ou <span class="math inline">\(T_0 &gt; k\)</span></li>
<li>Unilateral à direita: <span class="math inline">\(T_0 &gt; k\)</span></li>
<li>Unilateral à esuqerda: <span class="math inline">\(T_0 &lt; -k\)</span></li>
</ul>
<p>Nas Figuras abaixo ilustram-se as regiões críticas para cada tipo de hipótese alternativa.</p>
<p><img src="inferencia_com_R_files/figure-html/unnamed-chunk-74-1.png" width="576" style="display: block; margin: auto;" /></p>
<p><img src="inferencia_com_R_files/figure-html/unnamed-chunk-75-1.png" width="576" style="display: block; margin: auto;" /></p>
<p><img src="inferencia_com_R_files/figure-html/unnamed-chunk-76-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>O procedimento usual de teste de hipóteses consiste em se fixar o nível de significância <span class="math inline">\(\alpha\)</span>, que, por definição, é a probabilidade de se cometer o erro tipo I:</p>
<p><span class="math display">\[\alpha = P(\text{erro tipo I}) = P(\text{rejeitar }H_0|H_0\text{ é verdadeira})\]</span></p>
<p>Assim, para cada tipo de hipótese alternativa a região crítica é identificada impondo-se a condição <span class="math inline">\(P(T \in RC|H0\text{ é verdadeira}) = \alpha\)</span></p>
<div id="bilateral-1" class="section level4" number="6.3.1.1">
<h4><span class="header-section-number">6.3.1.1</span> Bilateral</h4>
<p>A região crítica é calculada como:</p>
<p><span class="math display">\[
\begin{aligned}
\alpha&amp;=P\left[T_0&lt;-k\right|T_0\sim t(n-1)]+P\left[T_0&gt;k\right|T_0\sim t(n-1)]\\
\alpha&amp;=2\times P\left[T_0&lt;-k\right|T_0\sim t(n-1)]\\
\frac{\alpha}{2}&amp;=P\left[T_0&gt;k\right|T_0\sim t(n-1)]
\end{aligned}
\]</span></p>
<p>Usando a notação <span class="math inline">\(t_{n;\alpha}\)</span> para denotar a abcissa da distribuição <span class="math inline">\(t\)</span> de Student com <span class="math inline">\(n\)</span> graus de liberdade que deixa área (probabilidade) <span class="math inline">\(\alpha\)</span> acima dela, resulta a seguinte região crítica para o teste bilateral:</p>
<p><span class="math display">\[T_0&lt;-t_{n-1;\frac{\alpha}{2}}~~~~~~\text{ou}~~~~~~T_0&gt;t_{n-1;\frac{\alpha}{2}}\]</span></p>
<p>Essa região crítica também pode ser escrita de outra forma usando a seguinte equivalência:</p>
<p><span class="math display">\[T_0&lt;-t_{n-1;\frac{\alpha}{2}}\Longrightarrow \frac{\bar X-\mu_0}{\frac{S}{\sqrt n}}&lt;-t_{n-1;\frac{\alpha}{2}}\Longrightarrow\bar X&lt;\mu_0-t_{n-1;\frac{\alpha}{2}}\frac{S}{\sqrt n}\]</span></p>
<p><span class="math display">\[T_0&gt;t_{n-1;\frac{\alpha}{2}}\Longrightarrow \frac{\bar X-\mu_0}{\frac{S}{\sqrt n}}&gt;t_{n-1;\frac{\alpha}{2}}\Longrightarrow\bar X&gt;\mu_0+t_{n-1;\frac{\alpha}{2}}\frac{S}{\sqrt n}\]</span></p>
</div>
<div id="unilateral-à-direita-1" class="section level4" number="6.3.1.2">
<h4><span class="header-section-number">6.3.1.2</span> Unilateral à direita</h4>
<p>A região crítica é calculada como:</p>
<p><span class="math display">\[
\begin{aligned}
\alpha&amp;=P\left[T_0&gt;k\right|T_0\sim t(n-1)]\\
t_{n-1;\alpha}&amp;=k
\end{aligned}
\]</span></p>
<p>ou seja, a região crítica é</p>
<p><span class="math display">\[T_0 &gt; t_{n-1;\alpha}\]</span></p>
<p>ou equivalentemente</p>
<p><span class="math display">\[\bar X&gt;\mu_0+t_{n-1;\alpha}\frac{S}{\sqrt n}\]</span></p>
</div>
<div id="unilateral-à-esquerda-1" class="section level4" number="6.3.1.3">
<h4><span class="header-section-number">6.3.1.3</span> Unilateral à esquerda</h4>
<p>De forma análoga, obtém-se a seguinte região crítica para o teste unilateral à esquerda:</p>
<p><span class="math display">\[T_0 &lt;- t_{n-1;\alpha}\]</span></p>
<p>ou equivalentemente</p>
<p><span class="math display">\[\bar X&lt;\mu_0-t_{n-1;\alpha}\frac{S}{\sqrt n}\]</span>
### Teste de Hipóteses vs Intervalo de Confiança</p>
<p>xxx</p>
</div>
</div>
<div id="valor-p-ou-p-valor-1" class="section level3" number="6.3.2">
<h3><span class="header-section-number">6.3.2</span> Valor P (ou p-valor)</h3>
<p>XXX</p>
</div>
<div id="exemplo-4" class="section level3" number="6.3.3">
<h3><span class="header-section-number">6.3.3</span> Exemplo</h3>
<p>Depois de uma pane geral no sistema de informação de uma empresa, o gerente administrativo deseja saber se houve alteração no tempo de processamento de determinada atividade. Antes da pane, o tempo de processamento podia ser aproximado por uma variável aleatória normal com média de 100 minutos. Uma amostra de 16 tempos de processamento após a pane revela uma média <span class="math inline">\(\bar x = 105,5\)</span> minutos e um desvio padrão <span class="math inline">\(s = 10\)</span> minutos. Ao nível de significância de 5%, qual é a conclusão sobre a alteração do tempo médio de processamento?</p>
<p><strong>Solução</strong></p>
<p>Como visto, as hipóteses do problema são:</p>
<p><span class="math display">\[
\begin{cases}
H_0:\mu=\mu_0 \\
H_1:\mu\ne\mu_0
\end{cases}
\]</span></p>
<p>Como a variância não é conhecida, temos que usar a distribuição <span class="math inline">\(t\)</span> de Student com <span class="math inline">\(n-1=16-1=15\)</span> graus de liberdade. Para um teste bilateral com nível de significância de 5%, a abscissa de interesse é aquela que deixa área de <span class="math inline">\(0,025\)</span> acima. Consultando a Tabela, resulta</p>
<p><span class="math display">\[t_{15;0,025}=2,131\]</span></p>
<p>A estatística de teste é</p>
<p><span class="math display">\[T_0=\frac{\bar X -100}{\frac{10}{\sqrt{16}}}\sim t(15)\]</span></p>
<p>e a região crítica é</p>
<p><span class="math display">\[T_0&lt;-2,131~~~~\text{ou}~~~~T_0&gt;2,131\]</span></p>
<p>O valor observado da estatísitca de teste é</p>
<p><span class="math display">\[T_0=\frac{105,5 -100}{\frac{10}{\sqrt{16}}}=2,2\]</span></p>
<p>Como esse valor pertence à região crítica, rejeitamos a hipótese nula e concluímos que houve alteração no tempo de processamento após a pane.</p>
<p>Em termos da média amostral, a região crítica é</p>
<p><span class="math display">\[\bar X&lt;100-2,131\times\frac{10}{\sqrt{16}}~~~~\text{ou}~~~~\bar X&gt;100+2,131\times\frac{10}{\sqrt{16}}\]</span></p>
<p>ou</p>
<p><span class="math display">\[\bar X&lt;105,33~~~~\text{ou}~~~~\bar X&gt;94,673\]</span></p>
<p>Comparando com a Região Crítica obtida no Exemplo 1 da seção anterior (<span class="math inline">\(\bar X &lt; 95.1\text{ ou }\bar X &gt; 104.9\)</span>), note que com o mesmo nível de significância, a região crítica no caso de variância desconhecida é mais extrema, refletindo a maior variabilidade da distribuição t-student.</p>
<p><img src="inferencia_com_R_files/figure-html/unnamed-chunk-77-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Para calcular o p-valor:</p>
<p><span class="math display">\[
\begin{aligned}
p-valor &amp;= 2\times P\left(\bar X&gt;105,5 \Big| \frac{\bar X-100}{\frac{10}{\sqrt 16}} \sim t(15)\right)\\
&amp;= 2\times P\left(t(15)&gt;\frac{105,5-100}{\frac{10}{\sqrt 16}}\right)\\
&amp;= 2\times P\left(t(15)&gt;2,2\right)\\
&amp;= 2\times 0, 02195 = 0, 0439
\end{aligned}
\]</span></p>
<p>Como <span class="math inline">\(p-valor &lt; 0,05\)</span>, rejeitamos <span class="math inline">\(H_0\)</span> ao nível de significância de 5%.</p>
</div>
</div>
<div id="t.h.-para-a-proporção-populacional" class="section level2" number="6.4">
<h2><span class="header-section-number">6.4</span> T.H. para a proporção populacional</h2>
<p>Já aprendemos a construir testes de hipóteses sobre a média de uma população normal com variância <span class="math inline">\(\sigma^2\)</span> conhecida. O procedimento baseou-se na distribuição amostral da média amostral que, com as hipóteses de normalidade e conhecimento da variância populacional, sabemos ser normal com a mesma média e variância <span class="math inline">\(\frac{\sigma^2}{n}\)</span>. Agora, iremos fazer uso do Teorema Limite Central para construir testes de hipóteses sobre proporções com base em amostras grandes. Vimos que, para amostras grandes, a distribuição amostral da proporção amostral pode ser aproximada por uma distribuição normal e, assim, o procedimento de teste de hipóteses será idêntico ao estudado sobre a média de uma população normal com variância <span class="math inline">\(\sigma^2\)</span> conhecida.</p>
<p>O contexto de interesse é o seguinte: temos uma população em que cada elemento é classificado de acordo com a presença ou ausência de determinada característica. Em termos de variável aleatória, essa população é representada por uma v.a. de Bernoulli, isto é:</p>
<p><span class="math display">\[
X=\begin{cases}
1,\text{  se elemento possui característica de interesse}\\
0,\text{  se elemento não possui característica de interesse}
\end{cases}
\]</span></p>
<p>Então, <span class="math inline">\(P(X = 1) = p\)</span>, <span class="math inline">\(E(X) = p\)</span> e <span class="math inline">\(V(X) = p(1-p)\)</span>. O parâmetro <span class="math inline">\(p\)</span> é também a proporção de elementos da população que possuem a caracterísitca de interesse. Em geral, esse parâmetro é desconhecido e queremos testar hipóteses feitas sobre seu possível valor.</p>
<p>Suponha, então, que dessa população seja extraída uma amostra aleatória simples <span class="math inline">\(X_1,\ldots,X_n\)</span> com reposição. Vimos que a proporção <span class="math inline">\(\hat P\)</span> de elementos na amostra que possuem a característica de interesse, definida por</p>
<p><span class="math display">\[\hat P = \frac{S_n}{n} = \frac{X_1+X_2+\ldots+X_n}{n}\]</span></p>
<p>é um estimador não-viesado para <span class="math inline">\(p\)</span> com variância <span class="math inline">\(\frac{p(1-p)}{n}\)</span>. Mais precisamente,</p>
<p><span class="math display">\[E(\hat P)=p\]</span></p>
<p><span class="math display">\[V(\hat P)=\frac{p(1-p)}{n}\]</span></p>
<div id="construindo-o-teste-de-hipóteses-2" class="section level3" number="6.4.1">
<h3><span class="header-section-number">6.4.1</span> Construindo o teste de hipóteses</h3>
<p>Como a proporção amostral é uma média de uma amostra aleatória simples de uma população com distribuição de Bernoulli com parâmetro <span class="math inline">\(p\)</span>, o Teorema Central do Limite nos diz, então, que a distribuição de <span class="math inline">\(\hat P\)</span> se aproxima de uma nornal com média <span class="math inline">\(p\)</span> e variância <span class="math inline">\(\frac{p(1-p)}{n}\)</span>.</p>
<p>Resumindo, temos o seguinte resultado:</p>
<p><span class="math display">\[\hat P \approx N\left(p,\frac{p(1-p)}{n}\right)\]</span></p>
<p>ou, equivalentemente,</p>
<p><span class="math display">\[\frac{\hat P-p}{\sqrt{\frac{p(1-p)}{n}}}\approx N(0,1)\]</span></p>
<p>Vamos ver, agora, como usar esse resultado para construir testes de hipóteses sobre a verdadeira proporção populacional <span class="math inline">\(p\)</span>.</p>
<p>A hipótese nula que consideraremos será uma hipótese simples:</p>
<p><span class="math display">\[H_0:p=p_0\]</span></p>
<p>As hipóteses alternativas possíveis são</p>
<ul>
<li>Bilateral: <span class="math inline">\(H_1:p\neq p_0\)</span></li>
<li>Unilateral à direita: <span class="math inline">\(H_1:p &gt; p_0\)</span></li>
<li>Unilateral à esquerda: <span class="math inline">\(H_1:p &lt; p_0\)</span></li>
</ul>
<p>Como no caso da média, a escolha das hipóteses nula e alternativa deve ser feita levando-se em conta que a hipótese nula deve ser uma hipótese simples. Assim, você deve “traduzir” a situação de interesse do problema em desigualdades envolvendo a proporção <span class="math inline">\(p\)</span>. A hipótese alternativa é a desigualdade que não inclui o sinal de <span class="math inline">\(=\)</span>. A estatística de teste é</p>
<p><span class="math display">\[Z=\frac{\hat P-p}{\sqrt{\frac{p(1-p)}{n}}}\approx N(0,1)\]</span></p>
<p>Dado um nível de significância <span class="math inline">\(\alpha\)</span>, a região crítica é definida como o conjunto de valores da estatísttca de teste que têm probabilidade pequena de ocorrerem sob a veracidade da hipótese nula. Assim, a região crítica é definida como o conjunto de valores de</p>
<p><span class="math display">\[Z_0=\frac{\hat P-p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}}\approx N(0,1)\]</span></p>
<p>com pequena probabilidade de ocorrência. Como estamos exatamente no mesmo procedimento de teste de hipóteses será idêntico ao estudado sobre a média de uma população normal com variância <span class="math inline">\(\sigma^2\)</span> conhecida,</p>
<ul>
<li><span class="math inline">\(Z_0 &lt; -Z_\frac{\alpha}{2}\)</span> ou <span class="math inline">\(Z_0&gt;Z_\frac{\alpha}{2}\)</span> (teste bilateral)</li>
<li><span class="math inline">\(Z_0 &gt; z_\alpha\)</span> (teste unilateral à direita)</li>
<li><span class="math inline">\(Z_0 &lt; -z_\alpha\)</span> (teste unilateral à esquerda)</li>
</ul>
<p>ou</p>
<ul>
<li><span class="math inline">\(\hat P &lt; p_0-Z_\frac{\alpha}{2}\sqrt{\frac{p_0(1-p_0)}{n}}\)</span> ou <span class="math inline">\(\hat P &gt; p_0+Z_\frac{\alpha}{2}\sqrt{\frac{p_0(1-p_0)}{n}}\)</span> (teste bilateral)</li>
<li><span class="math inline">\(\hat P &gt; p_0+Z_\alpha\sqrt{\frac{p_0(1-p_0)}{n}}\)</span> (teste unilateral à direita)</li>
<li><span class="math inline">\(\hat P &lt; p_0-Z_\alpha\sqrt{\frac{p_0(1-p_0)}{n}}\)</span> (teste unilateral à direita)</li>
</ul>
</div>
<div id="valor-p-ou-p-valor-2" class="section level3" number="6.4.2">
<h3><span class="header-section-number">6.4.2</span> Valor P (ou p-valor)</h3>
<p>Como já visto, o valor P é a probabilidade de se obter um valor tão ou mais extremo (na direção da hipótese alternativa) que o valor observado da estatística de teste. Denotando por <span class="math inline">\(Z_0\)</span> o valor observado da estatística de teste, temos as seguintes possibilidades:</p>
<ul>
<li><span class="math inline">\(\text{p-valor}=2\times P(Z&gt;|Z_0|)\)</span> (teste bilateral)</li>
<li><span class="math inline">\(\text{p-valor}= P(Z&gt;|Z_0|)\)</span> (teste unilateral à direita ou à esquerda)</li>
</ul>
<p>Valores pequenos de <span class="math inline">\(\text{p-valor}\)</span> indicam que o valor observado é pouco provável de ocorrer sob a hipótese nula; logo, valores pequenos de <span class="math inline">\(\text{p-valor}\)</span> levam à rejeição da hipótese nula. A hipótese nula é rejeitada a qualquer nível de significância <span class="math inline">\(\alpha \geq \text{p-valor}\)</span>.</p>
</div>
<div id="exemplo-5" class="section level3" number="6.4.3">
<h3><span class="header-section-number">6.4.3</span> Exemplo</h3>
<p>Uma amostra de 64 elementos é usada para testar</p>
<p><span class="math display">\[
\begin{cases}
H_0:p=0,35 \\
H_1:p\neq 0,35
\end{cases}
\]</span></p>
<p>Estabeleça a região crítica para o nível de significância de 1%. Se a proporção amostral para esta amostra é <span class="math inline">\(\hat P = 0,26\)</span>, calcule o <span class="math inline">\(\text{p-valor}\)</span>.</p>
<p><strong>Solução</strong></p>
<p>Com <span class="math inline">\(\alpha=0,01\)</span> e um teste bilateral, resulta que <span class="math inline">\(z_{0,005}=2,59\)</span>. A estatística de teste é</p>
<p><span class="math display">\[Z_0=\frac{0,26-0,35}{\sqrt{\frac{0,35\times 0,65}{64}}}=-1,51\]</span></p>
<p>e a região crítica é</p>
<p><span class="math display">\[Z_0&lt;-2,59~~~~\text{ou}~~~~Z_0&gt;2,59\]</span></p>
<p>Como o teste é bilateral, o <span class="math inline">\(\text{p-valor}\)</span> é calculado como</p>
<p><span class="math display">\[
\begin{aligned}
\text{p-valor} &amp;= 2\times P(Z&gt;|-1,51|) \\
&amp;= 2\times 0,0655\\
&amp;= 0,131
\end{aligned}
\]</span></p>
<p>Como o <span class="math inline">\(\text{p-valor}\)</span> é grande, não se rejeita a hipótese nula, ou seja, a probabilidade de se obter um valor tão extremo quanto o observado é alta, se <span class="math inline">\(H_0\)</span> for verdadeira. A hipótese nula só seria rejeitada para níveis de significância maiores que 13,1%.</p>
</div>
</div>
<div id="t.h.-para-a-variância-de-uma-normal" class="section level2" number="6.5">
<h2><span class="header-section-number">6.5</span> T.H. para a variância de uma Normal</h2>
<p>Agora completaremos o estudo de teste de hipóteses sobre parâmetros de uma população, analisando o caso da variância de uma população normal. Assim como na construção de intervalos de confiança, nossa estatística de teste tem distribuição qui-quadrado e a região crítica, como antes, será formada pelos valores pouco prováveis desta estatística de teste sob a hipótese nula.</p>
<p>Considere uma população descrita por uma variável aleatória normal com média <span class="math inline">\(\mu\)</span> e variância <span class="math inline">\(\sigma^2: X\sim N(\mu; \sigma^2)\)</span>. Nosso interesse é testar hipóteses sobre a a variância <span class="math inline">\(\sigma^2\)</span> a partir de uma amostra aleatória simples <span class="math inline">\(X_1, X_2,\ldots, X_n\)</span>. Como visto anteriormente, a estatística</p>
<p><span class="math display">\[\chi^2=\frac{(n-1)S^2}{\sigma^2}\]</span></p>
<p>tem distribuição qui-quadrado com <span class="math inline">\(n-1\)</span> graus de liberdade.</p>
<p>De posse desta estatística de teste, o procedimento de construção do teste é idêntico ao visto nos últimos capítulos: identificadas a hipótese nula (sempre na forma de uma hipótese simples <span class="math inline">\(\sigma^2=\sigma^2_0\)</span>) e a hipótese alternativa, a região crítica é formada pelos valores da estatística de teste pouco prováveis sob <span class="math inline">\(H_0\)</span>. O nível de significância e o tipo de hipótese alternativa permitem a identificação precisa do que são “valores pouco prováveis”: são valores na(s) cauda(s) da distribuição de <span class="math inline">\(\chi^2\)</span> quando a hipótese nula é verdadeira.</p>
<div id="construindo-o-teste-de-hipóteses-3" class="section level3" number="6.5.1">
<h3><span class="header-section-number">6.5.1</span> Construindo o teste de hipóteses</h3>
<p>Seja <span class="math inline">\(X_1, X_2,\ldots, X_n\)</span> uma amostra aleatória simples de uma população <span class="math inline">\(X\)</span> cuja distribuição é <span class="math inline">\(N(\mu,\sigma^2)\)</span>. Nosso interesse é testar alguma hipótese sobre a variância <span class="math inline">\(\sigma^2\)</span>, que é estimada por</p>
<p><span class="math display">\[S^2=\frac{1}{n-1}\sum_{i=1}^n(X_i-\bar X)^2\]</span></p>
<p>Lembre-se que <span class="math inline">\(S^2\)</span> é um estimador não-viesado de <span class="math inline">\(\sigma^2\)</span>.</p>
<p>A hipótese nula que iremos considerar será</p>
<p><span class="math display">\[H_0:\sigma^2=\sigma^2_0\]</span></p>
<p>As possíveis formas da hipótese alternativa são:</p>
<ul>
<li>Bilateral: <span class="math inline">\(H_1:\sigma^2\neq \sigma^2_0\)</span></li>
<li>Unilateral à direita: <span class="math inline">\(H_1:\sigma^2 &gt; \sigma^2_0\)</span></li>
<li>Unilateral à esquerda: <span class="math inline">\(H_1:\sigma^2 &lt; \sigma^2_0\)</span></li>
</ul>
<p>Como o teste é sobre a variância de uma população normal, a estatística amostral a ser utilizada é</p>
<p><span class="math display">\[\frac{(n-1)S^2}{\sigma^2}\sim \chi^2_{n-1}\]</span></p>
<p>O procedimento de decisão é definido em termos da hipótese nula <span class="math inline">\(H_0\)</span> e as decisões possíveis são (i) rejeitar ou (ii) não rejeitar <span class="math inline">\(H_0\)</span>. Conforme já visto, existem duas possibilidades de erro:</p>
<ul>
<li>Erro tipo I: rejeitar <span class="math inline">\(H_0\)</span> quando <span class="math inline">\(H_0\)</span> é verdadeira</li>
<li>Erro tipo II: não rejeitar <span class="math inline">\(H_0\)</span> quando <span class="math inline">\(H_0\)</span> é falsa</li>
</ul>
<p>A regra de decisão consiste em definir a região crítica RC como o conjunto de valores cuja probabilidade de ocorrência é pequena sob a hipótese de veracidade de <span class="math inline">\(H_0\)</span>. Logo, nossa regra de decisão se baseia na estatística de teste</p>
<p><span class="math display">\[X_0=\frac{(n-1)S^2}{\sigma^2_0}\sim \chi^2_{n-1}\]</span></p>
<p>Os valores com pequena probabilidade de ocorrência estão nas caudas da distribuição. Assim, a região crítica para cada tipo de hipótese alternativa é definida como segue:</p>
<ul>
<li><span class="math inline">\(X_0&lt;k_I\)</span> ou <span class="math inline">\(X^2_0&gt;k_S\)</span> (teste bilateral)</li>
<li><span class="math inline">\(X_0&gt;k_S\)</span> (teste unilateral à direita)</li>
<li><span class="math inline">\(X_0&lt;k_I\)</span> (teste unilateral à esquerda)</li>
</ul>
<div id="bilateral-2" class="section level4" number="6.5.1.1">
<h4><span class="header-section-number">6.5.1.1</span> Bilateral</h4>
<p>O procedimento usual de teste de hipóteses consiste em se fixar o nível de significância <span class="math inline">\(\alpha\)</span>, que, por definição, é a probabilidade do erro tipo I:</p>
<p><span class="math display">\[\alpha=P(\text{erro tipo I})=(\text{rejeitar }H_0|H_0~\text{é verdadeira})\]</span></p>
<p>Assim, para cada tipo de hipótese alternativa a região crítica é identificada impondo-se a condição</p>
<p><span class="math display">\[P(X_0 \in RC|H_0~\text{é verdadeira})=\alpha\]</span></p>
<p>A região crítica é calculada como:</p>
<p><span class="math display">\[P\left[X_0&lt;k_I|X_0\sim\chi^2_{n-1}\right]+P\left[X_0&gt;k_S|X_0\sim\chi^2_{n-1}\right]=\alpha\]</span></p>
<p>Mesmo a distribuição qui-quadrado não sendo simétrica, é prática usual dividir a probabilidade de erro em partes iguais, ou seja, os limites da região crítica são definidos de modo que</p>
<ul>
<li><span class="math inline">\(P\left[X_0&lt;k_I|X_0\sim\chi^2_{n-1}\right]=\frac{\alpha}{2}\)</span></li>
<li><span class="math inline">\(P\left[X_0&gt;k_S|X_0\sim\chi^2_{n-1}\right]=\frac{\alpha}{2}\)</span></li>
</ul>
<p><img src="inferencia_com_R_files/figure-html/unnamed-chunk-78-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Usando a notação <span class="math inline">\(\chi^2_{n,\alpha}\)</span> para denotar a abscissa da distribuição qui-quadrado com <span class="math inline">\(n\)</span> graus de liberdade que deixa área (probabilidade) <span class="math inline">\(\alpha\)</span> acima dela, resulta a seguinte região crítica para o teste bilateral:</p>
<p><span class="math display">\[X_0&lt;\chi^2_{n-1,1-\frac{\alpha}{2}}~~~~\text{ou}~~~~X_0&gt;\chi^2_{n-1,\frac{\alpha}{2}}\]</span></p>
<p>ou também,</p>
<p><span class="math display">\[S^2&lt;\frac{n-1}{\sigma^2_0}\chi^2_{n-1,1-\frac{\alpha}{2}}~~~~\text{ou}~~~~S^2&gt;\frac{n-1}{\sigma^2_0}\chi^2_{n-1,\frac{\alpha}{2}}\]</span></p>
</div>
<div id="unilateral-à-direita-2" class="section level4" number="6.5.1.2">
<h4><span class="header-section-number">6.5.1.2</span> Unilateral à direita</h4>
<p>A região crítica é calculada como:</p>
<p><span class="math display">\[P\left[X_0&gt;k_S|X_0\sim\chi^2_{n-1}\right]=\alpha\Longrightarrow k_S=\chi^2_{n-1,\alpha}\]</span></p>
<p>ou seja, a região crítica é</p>
<p><span class="math display">\[X_0&gt;\chi^2_{n-1,\alpha}\]</span></p>
<p>ou também,</p>
<p><span class="math display">\[S^2&gt;\frac{n-1}{\sigma^2_0}\chi^2_{n-1,\alpha}\]</span>.</p>
<p><img src="inferencia_com_R_files/figure-html/unnamed-chunk-79-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="unilateral-à-esquerda-2" class="section level4" number="6.5.1.3">
<h4><span class="header-section-number">6.5.1.3</span> Unilateral à esquerda</h4>
<p>De forma análoga, obtém-se a seguinte região crítica para o teste unilateral à esquerda:</p>
<p><span class="math display">\[X_0&lt;\chi^2_{n-1,1-\alpha}\]</span></p>
<p>ou também,</p>
<p><span class="math display">\[S^2&lt;\frac{n-1}{\sigma^2_0}\chi^2_{n-1,1-\alpha}\]</span>.</p>
<p><img src="inferencia_com_R_files/figure-html/unnamed-chunk-80-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="valor-p" class="section level3" number="6.5.2">
<h3><span class="header-section-number">6.5.2</span> Valor P</h3>
<p>Como já visto, o valor P é a probabilidade de se obter um valor tão ou mais extremo (na direção da hipótese alternativa) que o valor observado da estatística de teste. Denotando por <span class="math inline">\(X_0\)</span> o valor observado da estatística de teste, temos as seguintes possibilidades:</p>
<ul>
<li><span class="math inline">\(\text{p-valor}=2\times \text{mín}\{P(\chi_{n-1}&gt;X_0),P(\chi_{n-1}&lt;X_0)\}\)</span> (teste bilateral)</li>
<li><span class="math inline">\(\text{p-valor}= P(\chi_{n-1}&gt;X_0)\)</span> (teste unilateral à direita)</li>
<li><span class="math inline">\(\text{p-valor}= P(\chi_{n-1}&lt;X_0)\)</span> (teste unilateral à esquerda)</li>
</ul>
<p>Valores pequenos de <span class="math inline">\(\text{p-valor}\)</span> indicam que o valor observado é pouco provável de ocorrer sob a hipótese nula; logo, valores pequenos de <span class="math inline">\(\text{p-valor}\)</span> levam à rejeição da hipótese nula. A hipótese nula é rejeitada a qualquer nível de significância <span class="math inline">\(\alpha \geq \text{p-valor}\)</span>.</p>
</div>
<div id="exemplo-6" class="section level3" number="6.5.3">
<h3><span class="header-section-number">6.5.3</span> Exemplo</h3>
<p>XXX</p>
</div>
</div>
<div id="t.h.-adequação-de-ajuste-goodness-of-fit" class="section level2" number="6.6">
<h2><span class="header-section-number">6.6</span> T.H. Adequação de Ajuste (Goodness of Fit)</h2>
<p>Os procedimentos de testes de hipóteses que discutimos nas seções prévias são projetados para problemas em que a população ou a distribuição de probabilidades seja conhecida e as hipóteses envolvam os parâmetros da distribuição.</p>
<p>Outro tipo de hipótese é frequentemente encontrada: <em>Não conhecemos a distribuição sob consideração da população e desejamos testar a hipótese de que uma distribuição particular será satisfatória como um modelo para a população</em></p>
<p>Por exemplo, podemos desejar testar a hipótese de que a população seja normal. Ou seja, as hipóteses são:</p>
<p><span class="math display">\[
\begin{cases}
H_0:~~\text{a forma da distribuição da população é (Normal, Poisson etc.)}\\
H_1:~~\text{a forma da distribuição da população não é (Normal, Poisson etc.)}
\end{cases}
\]</span></p>
<p>Utilizaremos aqui o <strong>teste de adequação de ajuste</strong>, baseado na distribuição qui-quadrado.</p>
<p>O procedimento de teste requer uma amostra de tamanho <span class="math inline">\(n\)</span>, proveniente da população cuja distribuição de probabilidades é desconhecida. Essas <span class="math inline">\(n\)</span> observações são arranjadas em um histograma de frequências, tendo <span class="math inline">\(k\)</span> intervalos de classe onde <span class="math inline">\(O_i\)</span> é a frequência observada no <span class="math inline">\(i\)</span>-ésimo intervalo de classe. A partir da distribuição de probabilidades utilizada na hipótese, calculamos a frequência esperada no <span class="math inline">\(i\)</span>-ésimo intervalo de classe, denotada como <span class="math inline">\(E_i\)</span>.</p>
<div id="construindo-o-teste-de-hipóteses-4" class="section level3" number="6.6.1">
<h3><span class="header-section-number">6.6.1</span> Construindo o teste de hipóteses</h3>
<p>A estatística de teste é:</p>
<p><span class="math display">\[\chi^2_0=\sum_{i=1}^n\frac{(O_i-E_i)^2}{E_i}\]</span></p>
<p>Se a população seguir a distribuição testada na hipótese nula, a estatística de teste <span class="math inline">\(\chi^2_0\)</span> terá, aproximadamente, uma distribuição qui-quadrado com <span class="math inline">\(k-p-1\)</span> graus de liberdade, em que <span class="math inline">\(p\)</span> representa o número de parâmetros da distribuição utilizada na hipótese, estimados pelas estatísticas amostrais.</p>
<p>Deve-se rejeitar a hipótese nula de que a distribuição da população é a distribuição utilizada na hipótese, se a estatística de teste for “muito grande.” Isto é, rejeitaríamos a um nível de significância <span class="math inline">\(\alpha\)</span>, se o valor calculado da estatística de teste <span class="math inline">\(\chi^2_0&gt;\chi^2_{k-p-1;\alpha}\)</span>.</p>
<p>Já o p-valor é calculado como <span class="math inline">\(P(\chi^2_{k-p-1;\alpha}&gt;\chi^2_0)\)</span>.</p>
<p>Um ponto a ser notado na aplicação desse procedimento de teste se refere à magnitude das <strong>frequências esperadas</strong>. Se essas frequências forem muito pequenas, então a estatística de teste <span class="math inline">\(\chi^2_0\)</span> não refletirá o desvio entre o observado e esperado, mas somente a pequena magnitude das frequências esperadas. Portanto, quando uma classe obtiver frequência esperada menor que 3, deve-se combiná-la a classe anterior (intervalos de classe não necessitam ter a mesma largura)</p>
</div>
<div id="exemplo-7" class="section level3" number="6.6.2">
<h3><span class="header-section-number">6.6.2</span> Exemplo</h3>
<p>Supõe-se que o número de defeito nas placas de circuito impresso siga a distribuição de Poisson. Uma amostra aleatória de <span class="math inline">\(n=60\)</span> placas impressas foi coletada e o número de defeitos, observado. Está correta a suposição?</p>
<table>
<thead>
<tr class="header">
<th>Número de Defeitos</th>
<th>Frequência Observada</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>32</td>
</tr>
<tr class="even">
<td>1</td>
<td>15</td>
</tr>
<tr class="odd">
<td>2</td>
<td>9</td>
</tr>
<tr class="even">
<td>3 (ou mais)</td>
<td>4</td>
</tr>
</tbody>
</table>
<p><strong>Solução</strong></p>
<p>A média da distribuição de Poisson considerada neste exemplo é desconhecida e tem de ser estimada a partir dos dados da amostra. Isto é, a estimativa do número médio de defeitos por placa é a média amostral, ou seja:</p>
<p><span class="math display">\[\frac{0\times32+1\times15+2\times9+3\times4}{32+15+9+4}=0.75\]</span></p>
<p>A partir da distribuição de Poisson com parâmetro <span class="math inline">\(0.75\)</span>, podemos calcular <span class="math inline">\(p_i\)</span>, a probabilidade teórica utilizada na hipótese, associada ao <span class="math inline">\(i\)</span>-ésimo intervalo de classe.</p>
<p>Uma vez que cada intervalo de classe corresponde a um número particular de defeitos, podemos encontrar <span class="math inline">\(p_i\)</span> como segue:</p>
<ul>
<li><span class="math inline">\(p_1=P(X=0)=\frac{e^{-0.75}(0.75)^0}{0!}=0.472\)</span></li>
<li><span class="math inline">\(p_2=P(X=1)=\frac{e^{-0.75}(0.75)^1}{1!}=0.354\)</span></li>
<li><span class="math inline">\(p_3=P(X=2)=\frac{e^{-0.75}(0.75)^2}{2!}=0.133\)</span></li>
<li><span class="math inline">\(p_4=P(X\geq3)=1-p_1-p_2-p_3=0.041\)</span></li>
</ul>
<p>As frequências esperadas são calculadas pela multiplicação do tamanho da amostra <span class="math inline">\(n=60\)</span> vezes as probabilidades <span class="math inline">\(p_i\)</span> (<span class="math inline">\(E_i=n\times p_i\)</span>):</p>
<ul>
<li><span class="math inline">\(E_1=60\times0.472=28.32\)</span></li>
<li><span class="math inline">\(E_2=60\times0.354=21.24\)</span></li>
<li><span class="math inline">\(E_3=60\times0.133=7.98\)</span></li>
<li><span class="math inline">\(E_4=60\times0.041=2.46\)</span></li>
</ul>
<p>Já que a frequência esperada em <span class="math inline">\(E_4\)</span> é menor do que 3, combinamos <span class="math inline">\(E_3\)</span> e <span class="math inline">\(E_4\)</span>.</p>
<table>
<thead>
<tr class="header">
<th>Número de Defeitos</th>
<th><span class="math inline">\(O_i\)</span></th>
<th><span class="math inline">\(E_i\)</span></th>
<th><span class="math inline">\(\frac{(O_i-E_i)^2}{E_i}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>32</td>
<td>28,32</td>
<td><span class="math inline">\(\frac{(32-28,32)^2}{28,32}=0.4782\)</span></td>
</tr>
<tr class="even">
<td>1</td>
<td>15</td>
<td>21,24</td>
<td><span class="math inline">\(\frac{(15-21,24)^2}{21,24}=1.8332\)</span></td>
</tr>
<tr class="odd">
<td>2 (ou mais)</td>
<td>13</td>
<td>10,44</td>
<td><span class="math inline">\(\frac{(13-10,44)^2}{10,44}=0.6277\)</span></td>
</tr>
<tr class="even">
<td>Total</td>
<td>60</td>
<td>60</td>
<td>2.9391</td>
</tr>
</tbody>
</table>
<p>Portanto, usando <span class="math inline">\(\alpha=0.05\)</span>, temos que:</p>
<ul>
<li><span class="math inline">\(H_0:\)</span> a forma da distribuição de defeitos é Poisson</li>
<li><span class="math inline">\(H_1:\)</span> a forma da distribuição de defeitos não é Poisson</li>
<li><span class="math inline">\(\chi^2_0=2.9391\)</span></li>
<li><span class="math inline">\(k-p-1=3-1-1=1\)</span> e <span class="math inline">\(\chi^2_{1;0.05}=3.841459\)</span></li>
</ul>
<p>Conclusão: como <span class="math inline">\(\chi^2_0(2.9391)&lt;\chi^2_{1;0.05}(3.841459)\)</span>, não podemos rejeitar a hipótese nula de que a distribuição de defeitos nas placas de circuito impresso é Poisson a um nível de significância de 5%.</p>
<p>Para calcular o p-valor, devemos fazer <span class="math inline">\(P(\chi_1^2&gt;2.9391)=0.087\)</span>, note portanto que <span class="math inline">\(p-valor&gt;0.05\)</span> o que nos faz não rejeitar a um nível de significância de 5%, porém <span class="math inline">\(p-valor&lt;0.1\)</span> o que nos faria rejeitar <span class="math inline">\(H_0\)</span> a um nível de significância de 10%.</p>
</div>
</div>
<div id="t.h.-para-a-tabela-de-contingência" class="section level2" number="6.7">
<h2><span class="header-section-number">6.7</span> T.H. para a Tabela de Contingência</h2>
<p>Muitas vezes, os <span class="math inline">\(n\)</span> elementos de uma amostra proveniente de uma população podem ser classificados de acordo com dois critérios diferentes. É então interessante saber se os dois métodos de classificação são estatisticamente independentes; por exemplo, podemos considerar a população de engenheiros se graduando e podemos desejar determinar se o salário inicial é independente das disciplinas acadêmicas.</p>
<p>Considere que o primeiro método de classificação tenha <span class="math inline">\(r\)</span> níveis e que o segundo método tenha <span class="math inline">\(c\)</span> níveis. Seja <span class="math inline">\(O_{ij}\)</span> a frequência observada para o nível <span class="math inline">\(i\)</span> do primeiro método de classificação e nível <span class="math inline">\(j\)</span> para o segundo método. Os dados, em geral, aparecem como na tabela a seguir, chamada de <strong>tabela de contingência</strong></p>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th>Colunas</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td>1</td>
<td>2</td>
<td>…</td>
<td><span class="math inline">\(c\)</span></td>
</tr>
<tr class="even">
<td>Linhas</td>
<td>1</td>
<td><span class="math inline">\(O_{11}\)</span></td>
<td><span class="math inline">\(O_{12}\)</span></td>
<td>…</td>
<td><span class="math inline">\(O_{1c}\)</span></td>
</tr>
<tr class="odd">
<td></td>
<td>2</td>
<td><span class="math inline">\(O_{21}\)</span></td>
<td><span class="math inline">\(O_{22}\)</span></td>
<td>…</td>
<td><span class="math inline">\(O_{2c}\)</span></td>
</tr>
<tr class="even">
<td></td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
<tr class="odd">
<td></td>
<td><span class="math inline">\(r\)</span></td>
<td><span class="math inline">\(O_{r1}\)</span></td>
<td><span class="math inline">\(O_{r2}\)</span></td>
<td>…</td>
<td><span class="math inline">\(O_{rc}\)</span></td>
</tr>
</tbody>
</table>
<p>Estamos interessados em testar a hipótese de que os métodos linha-coluna de classificação são independentes. Se rejeitarmos essa hipótese, concluiremos que haverá alguma interação entre os dois critérios de classificação</p>
<p>Portanto, as hipóteses são:</p>
<p><span class="math display">\[
\begin{cases}
H_0:~~\text{os métodos de classificação são independentes}\\
H_1:~~\text{há interação entre os métodos de classificação (dependentes)}
\end{cases}
\]</span></p>
<p>Os procedimentos exatos de teste são difíceis de obter, porém uma estatística de teste aproximada é válida para <span class="math inline">\(n\)</span> grande. Seja <span class="math inline">\(p_{ij}\)</span> a probabilidade de um elemento selecionado aleatoriamente cair na <span class="math inline">\(ij\)</span>-ésima célula, dado que as duas classificações são independentes. Então, <span class="math inline">\(p_{ij}=u_{i}v_{j}\)</span> em que <span class="math inline">\(u_{i}\)</span> é a probabilidade de um elemento selecionado cair aleatoriamente na linha classe <span class="math inline">\(i\)</span> e <span class="math inline">\(v_j\)</span> é a probabilidade de um elemento selecionado aleatoriamente cair na coluna classe <span class="math inline">\(j\)</span>. Agora, supondo independência, os estimadores <span class="math inline">\(u_i\)</span> e <span class="math inline">\(v_j\)</span> são:
<span class="math display">\[\hat u_i=\frac{1}{n}\sum_{j=1}^cO_{ij} \text{ e } \hat v_j=\frac{1}{n}\sum_{i=1}^rO_{ij}\]</span></p>
<p>Logo, a frequência esperada de cada célula é</p>
<p><span class="math display">\[E_{ij}=n\hat u_i\hat v_j=\frac{1}{n}\sum_{j=1}^cO_{ij}\sum_{i=1}^rO_{ij}\]</span></p>
<div id="construindo-o-teste-de-hipóteses-5" class="section level3" number="6.7.1">
<h3><span class="header-section-number">6.7.1</span> Construindo o teste de hipóteses</h3>
<p>Assim, para <span class="math inline">\(n\)</span> grande, a estatística de teste tem uma distribuição aproximada qui-quadrado com <span class="math inline">\((r-1)(c-1)\)</span> graus de liberdade, se a hipótese nula for verdadeira:</p>
<p><span class="math display">\[\chi^2_0=\sum_{j=1}^c\sum_{i=1}^r\frac{(O_{ij}-E_{ij})^2}{E_{ij}}\]</span></p>
<p>Rejeita-se a hipótese de independência, se o valor observado da estatística de teste <span class="math inline">\(\chi^2_0&gt;\chi^2_{(r-1)(c-1);\alpha}\)</span>. Já o p-valor é calculado como <span class="math inline">\(P(\chi^2_{(r-1)(c-1)}&gt;\chi^2_0)\)</span>.</p>
</div>
<div id="exemplo-8" class="section level3" number="6.7.2">
<h3><span class="header-section-number">6.7.2</span> Exemplo</h3>
<p>Uma companhia tem de escolher entre três planos de saúde. O gerente deseja saber se a preferência para os planos é independente da classificação do trabalho e quer usar <span class="math inline">\(\alpha=0.05\)</span>. As opiniões de uma amostra aleatória de 500 empregados foram coletadas:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th>Plano de saúde</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>Total</td>
</tr>
<tr class="even">
<td>Classificação</td>
<td>Assalariados</td>
<td>160</td>
<td>140</td>
<td>40</td>
<td>340</td>
</tr>
<tr class="odd">
<td></td>
<td>Diaristas</td>
<td>40</td>
<td>60</td>
<td>60</td>
<td>160</td>
</tr>
<tr class="even">
<td></td>
<td>Total</td>
<td>200</td>
<td>200</td>
<td>100</td>
<td>500</td>
</tr>
</tbody>
</table>
<p><strong>Solução</strong></p>
<p>Para calcular as frequências esperadas, temos primeiro que calcular:</p>
<ul>
<li><span class="math inline">\(\hat u_1=\frac{340}{500}=0.68\)</span></li>
<li><span class="math inline">\(\hat u_2=\frac{160}{500}=0.32\)</span></li>
<li><span class="math inline">\(\hat v_1=\frac{200}{500}=0.40\)</span></li>
<li><span class="math inline">\(\hat v_2=\frac{200}{500}=0.40\)</span></li>
<li><span class="math inline">\(\hat v_3=\frac{100}{500}=0.20\)</span></li>
</ul>
<p>Agora,</p>
<ul>
<li><span class="math inline">\(E_{11} = n \hat u_1 \hat v_1 = 500\times 0.68 \times 0.40 = 136\)</span></li>
<li><span class="math inline">\(E_{12} = n \hat u_1 \hat v_2 = 500\times 0.68 \times 0.40 = 136\)</span></li>
<li><span class="math inline">\(E_{13} = n \hat u_1 \hat v_3 = 500\times 0.68 \times 0.20 = 68\)</span></li>
<li><span class="math inline">\(E_{21} = n \hat u_2 \hat v_1 = 500\times 0.32 \times 0.40 = 64\)</span></li>
<li><span class="math inline">\(E_{22} = n \hat u_2 \hat v_2 = 500\times 0.32 \times 0.40 = 64\)</span></li>
<li><span class="math inline">\(E_{23} = n \hat u_2 \hat v_2 = 500\times 0.32 \times 0.20 = 32\)</span></li>
</ul>
<p>As frequências esperadas são mostradas na tabela a seguir:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th>Plano de saúde</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>Total</td>
</tr>
<tr class="even">
<td>Classificação</td>
<td>Assalariados</td>
<td>136</td>
<td>136</td>
<td>68</td>
<td>340</td>
</tr>
<tr class="odd">
<td></td>
<td>Diaristas</td>
<td>64</td>
<td>64</td>
<td>32</td>
<td>160</td>
</tr>
<tr class="even">
<td></td>
<td>Total</td>
<td>200</td>
<td>200</td>
<td>100</td>
<td>500</td>
</tr>
</tbody>
</table>
<p>Portanto, usando <span class="math inline">\(\alpha=0.05\)</span>, temos que:</p>
<p><span class="math display">\[
\begin{cases}
H_0:~~\text{a preferência é independente da classificação de trabalho}\\
H_1:~~\text{a preferência depende da classificação de trabalho}
\end{cases}
\]</span></p>
<p>Então,</p>
<p><span class="math inline">\((r-1)(c-1)=(2-1)(3-1)=2\)</span> e <span class="math inline">\(\chi^2_{2;0.05}=5.991465\)</span></p>
<p>E <span class="math inline">\(\frac{(O_{ij}-E_{ij})^2}{E_{ij}}\)</span>, resultando em:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th>j</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td>1</td>
<td>2</td>
<td>3</td>
<td><span class="math inline">\(\sum\)</span></td>
</tr>
<tr class="even">
<td>i</td>
<td>1</td>
<td>4.235294</td>
<td>0.1176471</td>
<td>11.52941</td>
<td>15.88235</td>
</tr>
<tr class="odd">
<td></td>
<td>2</td>
<td>9</td>
<td>0.25</td>
<td>24.5</td>
<td>33.75</td>
</tr>
<tr class="even">
<td></td>
<td><span class="math inline">\(\sum\)</span></td>
<td>13.2352941</td>
<td>0.3676471</td>
<td>36.0294118</td>
<td>49.63235</td>
</tr>
</tbody>
</table>
<p>Conclusão: como <span class="math inline">\(\chi^2_0(49.63)&gt;\chi^2_{2;0.05}(5.99)\)</span>, rejeita-se a hipótese nula de independência a um nível de significância de 5%.</p>
<p>Para calcular o p-valor, devemos fazer <span class="math inline">\(P(\chi_2^2&gt;49.63)=1.67\times 10^{-11}\)</span>, note portanto que o p-valor é extremamente pequeno, o que nos faz rejeitar a hipótese nula a um nível de significância de 5% e a níveis menores também.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="intervalo-de-confiança.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="inferência-estatística-para-duas-populações.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/06-teste_de_hipotese.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["inferencia_com_R.pdf", "inferencia_com_R.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
